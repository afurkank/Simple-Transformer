{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWSq1ZN0MjIf",
        "outputId": "2bb17b8b-503d-4698-b748-83e2d4db8011"
      },
      "outputs": [],
      "source": [
        "!pip install tokenizers\n",
        "!pip install torchdata\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M1dD0NMEMjIh"
      },
      "outputs": [],
      "source": [
        "'''Hyperparameters'''\n",
        "\n",
        "''' Data Parameters '''\n",
        "MAX_LEN = 64\n",
        "VOCAB_SIZE = 32768\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "BATCH_SIZE = 128\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "''' Model Parameters '''\n",
        "D_MODEL = 512\n",
        "D_H = 8\n",
        "D_FF = 2048\n",
        "EMBEDDING_SIZE = 512\n",
        "N = 3\n",
        "''' Training Parameters '''\n",
        "DROPOUT = 0.2\n",
        "LR = 0.0001\n",
        "BETAS = (0.9, 0.98)\n",
        "EPS = 1e-9\n",
        "EPOCHS = 18\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l7QQ1zDWMjIj"
      },
      "outputs": [],
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "f = open(\"parallelcorpus.txt\", \"a\")\n",
        "\n",
        "for i in train_iter:\n",
        "  for x in [x.rstrip(\"\\n\") for x in i]:\n",
        "    f.write(x)\n",
        "    f.write(' ')\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AO-nW7opMjIk"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[BOS]\", \"[EOS]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "tokenizer.train(['parallelcorpus.txt'], trainer)\n",
        "\n",
        "tokenizer.enable_padding(pad_id=1, length=MAX_LEN)\n",
        "tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"[BOS] $A [EOS]\",\n",
        "    special_tokens=[\n",
        "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
        "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\")),\n",
        "    ],\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_enc = tokenizer.encode(src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(torch.tensor(src_enc.ids))\n",
        "\n",
        "        tgt_enc = tokenizer.encode(tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_batch.append(torch.tensor(tgt_enc.ids))\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JUJ3J_o1MjIl"
      },
      "outputs": [],
      "source": [
        "test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)\n",
        "test_dataloader = DataLoader(test_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W3rOmg4YMjIl"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size=32678, embedding_size=512, pad_mask=1):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size, padding_idx=pad_mask, device=DEVICE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x) * math.sqrt(self.embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XuvYlXDuMjIm"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.d_h = d_h\n",
        "        self.d_k = d_model // d_h\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Linear = nn.Linear(d_model, d_model)\n",
        "        self.normalize1 = nn.LayerNorm(d_model)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.normalize2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, x_mask=None):\n",
        "        multi_head = []\n",
        "        for i in range(self.d_h):\n",
        "            query = self.linears[3*i](x)\n",
        "            key = self.linears[3*i + 1](x)\n",
        "            value = self.linears[3*i + 2](x)\n",
        "            scaledDotProd = (query @ key.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
        "            if x_mask is not None:\n",
        "                scaledDotProd = scaledDotProd.masked_fill(x_mask==0, float('-inf'))\n",
        "            soft = F.softmax(scaledDotProd, dim=-1)\n",
        "            soft = self.dropout(soft)\n",
        "            attn =  soft @ value\n",
        "            multi_head.append(attn)\n",
        "        selfAttn = self.Linear(torch.cat((multi_head), -1))\n",
        "        addNorm = self.normalize1(x + selfAttn)\n",
        "        encoderOutput = self.normalize2(x + self.feed_forward(addNorm))\n",
        "        return encoderOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cfHw7_VuMjIn"
      },
      "outputs": [],
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, \n",
        "                 dropout=0.1, N=6):\n",
        "        super(EncoderStack, self).__init__()\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Encoder Layer N Times\n",
        "\n",
        "    def forward(self, x, x_mask=None):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x, x_mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gaZLO3lsMjIn"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.d_h = d_h\n",
        "        self.d_k = d_model // d_h\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)])\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.firstLinear = nn.Linear(d_h * self.d_k, d_model)\n",
        "        self.normalize1 = nn.LayerNorm(d_model)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.secondLinear = nn.Linear(d_h * d_model, d_model)\n",
        "        self.normalize2 = nn.LayerNorm(d_model)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.normalize3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, y, y_mask=None):\n",
        "        multi_head1 = []\n",
        "        multi_head2 = []\n",
        "\n",
        "        # FIRST ATTENTION LAYER\n",
        "        ''' Same as encoder, but here we have tgt(target) as the decoder's input '''\n",
        "        for i in range(self.d_h):\n",
        "            query = self.linears[3*i](y)\n",
        "            key = self.linears[3*i+1](y)\n",
        "            value = self.linears[3*i+2](y)\n",
        "            scaledDotProd = (query @ key.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
        "            if y_mask is not None:\n",
        "                scaledDotProd = scaledDotProd.masked_fill(y_mask==0, float('-inf'))\n",
        "            soft = F.softmax(scaledDotProd, dim=-1)\n",
        "            soft = self.dropout1(soft)\n",
        "            attn =  soft @ value\n",
        "            multi_head1.append(attn)\n",
        "        selfAttn = self.firstLinear(torch.cat((multi_head1), dim=-1))\n",
        "        addNorm1 = self.normalize1(y + selfAttn)\n",
        "\n",
        "        # SECOND ATTENTION LAYER\n",
        "        ''' Attention layer, instead of V and K matrices, we use the output of the encoder '''\n",
        "        for i in range(self.d_h):\n",
        "            scaledDotProd = (addNorm1 @ x.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
        "            soft = F.softmax(scaledDotProd, dim=-1)\n",
        "            soft = self.dropout2(soft)\n",
        "            attn = soft @ x\n",
        "            multi_head2.append(attn)\n",
        "        crossAttn = self.secondLinear(torch.cat((multi_head2), dim=-1))\n",
        "        addNorm2 = self.normalize2(y + crossAttn)\n",
        "        decoderOutput = self.normalize3(y + self.feed_forward(addNorm2))\n",
        "        return decoderOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NFSeeoKTMjIo"
      },
      "outputs": [],
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, \n",
        "                 dropout=0.1, N=6):\n",
        "        super(DecoderStack, self).__init__()\n",
        "        self.decoders = nn.ModuleList([DecoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Decoder Layer N Times\n",
        "\n",
        "    def forward(self, x, y, y_mask=None):\n",
        "        for decoder in self.decoders:\n",
        "            y = decoder(x, y, y_mask)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tx4vpT4725w3"
      },
      "outputs": [],
      "source": [
        "class Mask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mask, self).__init__()\n",
        "    \n",
        "    def forward(self, batch_dim, seq_len):\n",
        "        mask = torch.tril(torch.ones((batch_dim, seq_len, seq_len), device=DEVICE))\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P4V-2pak25w4"
      },
      "outputs": [],
      "source": [
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self, embedding_size=512, n=10000):\n",
        "        super(Positional_Encoding, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n = n\n",
        "    def forward(self, seq_len):\n",
        "        P = torch.zeros(seq_len, self.embedding_size, device=DEVICE)\n",
        "        for k in range(seq_len):\n",
        "            for i in range(self.embedding_size // 2):\n",
        "                denominator = math.pow(self.n, 2*i/self.embedding_size)\n",
        "                P[k, 2*i] = math.sin(k/denominator)\n",
        "                P[k, 2*i+1] = math.cos(k/denominator)\n",
        "        return P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Eejkpbku25wz"
      },
      "outputs": [],
      "source": [
        "class GenerateLogits(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super(GenerateLogits, self).__init__()\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lsNHTQTPMjIo"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_h = 8, d_ff=2048, \n",
        "                 embedding_size=512, vocab_size=32768, \n",
        "                 dropout=0.1, num_coder_layers=6):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embed = Embedding(vocab_size, embedding_size, pad_mask=1)\n",
        "        self.positional = Positional_Encoding(embedding_size, 10000)\n",
        "        self.masking = Mask()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.encoderStack = EncoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "        self.decoderStack = DecoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "        self.generate = GenerateLogits(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        assert x.shape[0] == y.shape[0]\n",
        "        batch_dim = x.shape[0]\n",
        "        src_seq_len, tgt_seq_len = x.shape[1], y.shape[1]\n",
        "        x_pos_encoding = self.positional(src_seq_len)\n",
        "        y_pos_encoding = self.positional(tgt_seq_len)\n",
        "        x_mask = self.masking(batch_dim, src_seq_len)\n",
        "        y_mask = self.masking(batch_dim, tgt_seq_len)\n",
        "        x, y = self.embed(x), self.embed(y)\n",
        "        x, y = x_pos_encoding + x, y_pos_encoding + y\n",
        "        x, y = self.dropout1(x), self.dropout2(y)\n",
        "        encoderOutput = self.encoderStack(x, x_mask)\n",
        "        decoderOutput = self.decoderStack(encoderOutput, y, y_mask)\n",
        "        logits = self.generate(decoderOutput)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n5c2hP21MjIp"
      },
      "outputs": [],
      "source": [
        "model = Transformer(d_model=D_MODEL, d_h=D_H, d_ff=D_FF, \n",
        "                    embedding_size=EMBEDDING_SIZE, \n",
        "                    vocab_size=VOCAB_SIZE, dropout=DROPOUT, \n",
        "                    num_coder_layers=N)\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z152c5EJWXYm"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DglT1Wd8LM0"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_test_loss(model: nn.Module, test_data: DataLoader, \n",
        "                      padding_index: int):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=padding_index)\n",
        "    loss = []\n",
        "    for src, tgt in test_data:\n",
        "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
        "        tgt_in = tgt[:, :-1] # inputs shifted left\n",
        "        tgt_out = tgt[:, 1:] # labels shifted right\n",
        "        logits = model(src, tgt_in).permute(0, 2, 1)\n",
        "        loss.append(criterion(logits, tgt_out).item())\n",
        "    average_loss = np.average(loss)\n",
        "    model.train()\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OfIu8IFjmbt"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, train_data: DataLoader, \n",
        "          test_data: DataLoader, learning_rate: int, \n",
        "          padding_idx: int, epoch_num: int, betas: Tuple, eps: int):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, eps=eps)\n",
        "    batch_train_loss = []\n",
        "    epoch_test_loss = []\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        print(\"#\"*67)\n",
        "        print(f'{\"#\"*20}Training begins for epoc {epoch:>2}{\"#\"*20}')\n",
        "        print(\"#\"*67)\n",
        "        epoch_train_loss = []\n",
        "        for _, (src, tgt) in enumerate(train_data):\n",
        "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
        "            tgt_in = tgt[:, :-1] # inputs shifted left\n",
        "            \n",
        "            logits = model(src, tgt_in).permute(0, 2, 1)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            tgt_out = tgt[:, 1:] # labels shifted right\n",
        "            loss = criterion(logits, tgt_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss.append(loss.item())\n",
        "            batch_train_loss.append(loss.item())\n",
        "    \n",
        "        ep_train_loss = np.average(epoch_train_loss)\n",
        "        print(f'Training is complete for epoch {epoch:>2}, average training loss for epoch {epoch:>2}: {ep_train_loss:>5.3f}')\n",
        "        test_loss = compute_test_loss(model, test_data, padding_idx)\n",
        "        print(f'Test loss for epoch {epoch:>2}: {test_loss:>5.3f}')\n",
        "        epoch_test_loss.append(test_loss)\n",
        "        print(\"-\"*67)\n",
        "    plt.plot(batch_train_loss, color='blue')\n",
        "    plt.title(\"Loss Graph\")\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"Loss per Batch\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epoch_test_loss, color='purple')\n",
        "    plt.title(\"Test Loss Graph\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1H4dfSdBLWPN",
        "outputId": "0a4e3f1a-7d61-468b-9fa9-a9f69d090693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################################################################\n",
            "####################Training begins for epoc  0####################\n",
            "###################################################################\n",
            "Training is complete for epoch  0, average training loss for epoch  0: 5.919\n",
            "Test loss for epoch  0: 4.608\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  1####################\n",
            "###################################################################\n",
            "Training is complete for epoch  1, average training loss for epoch  1: 4.164\n",
            "Test loss for epoch  1: 3.821\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  2####################\n",
            "###################################################################\n",
            "Training is complete for epoch  2, average training loss for epoch  2: 3.595\n",
            "Test loss for epoch  2: 3.405\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  3####################\n",
            "###################################################################\n",
            "Training is complete for epoch  3, average training loss for epoch  3: 3.243\n",
            "Test loss for epoch  3: 3.127\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  4####################\n",
            "###################################################################\n",
            "Training is complete for epoch  4, average training loss for epoch  4: 2.958\n",
            "Test loss for epoch  4: 2.893\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  5####################\n",
            "###################################################################\n",
            "Training is complete for epoch  5, average training loss for epoch  5: 2.717\n",
            "Test loss for epoch  5: 2.728\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  6####################\n",
            "###################################################################\n",
            "Training is complete for epoch  6, average training loss for epoch  6: 2.515\n",
            "Test loss for epoch  6: 2.583\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  7####################\n",
            "###################################################################\n",
            "Training is complete for epoch  7, average training loss for epoch  7: 2.340\n",
            "Test loss for epoch  7: 2.477\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  8####################\n",
            "###################################################################\n",
            "Training is complete for epoch  8, average training loss for epoch  8: 2.189\n",
            "Test loss for epoch  8: 2.378\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  9####################\n",
            "###################################################################\n",
            "Training is complete for epoch  9, average training loss for epoch  9: 2.052\n",
            "Test loss for epoch  9: 2.305\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 10####################\n",
            "###################################################################\n",
            "Training is complete for epoch 10, average training loss for epoch 10: 1.936\n",
            "Test loss for epoch 10: 2.242\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 11####################\n",
            "###################################################################\n",
            "Training is complete for epoch 11, average training loss for epoch 11: 1.830\n",
            "Test loss for epoch 11: 2.199\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 12####################\n",
            "###################################################################\n",
            "Training is complete for epoch 12, average training loss for epoch 12: 1.735\n",
            "Test loss for epoch 12: 2.157\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 13####################\n",
            "###################################################################\n",
            "Training is complete for epoch 13, average training loss for epoch 13: 1.648\n",
            "Test loss for epoch 13: 2.123\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 14####################\n",
            "###################################################################\n",
            "Training is complete for epoch 14, average training loss for epoch 14: 1.574\n",
            "Test loss for epoch 14: 2.104\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 15####################\n",
            "###################################################################\n",
            "Training is complete for epoch 15, average training loss for epoch 15: 1.501\n",
            "Test loss for epoch 15: 2.075\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 16####################\n",
            "###################################################################\n",
            "Training is complete for epoch 16, average training loss for epoch 16: 1.436\n",
            "Test loss for epoch 16: 2.066\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 17####################\n",
            "###################################################################\n",
            "Training is complete for epoch 17, average training loss for epoch 17: 1.371\n",
            "Test loss for epoch 17: 2.065\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train(model, train_dataloader, test_dataloader, \n",
        "      learning_rate=LR, padding_idx=PAD_IDX, \n",
        "      epoch_num=EPOCHS, betas=BETAS, eps=EPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL1Ka42zXlfq",
        "outputId": "5df2f3ee-b31b-461a-a713-ad702ea02124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 64])\n",
            "torch.Size([5, 64])\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "src, tgt = next(iter(test_dataloader))\n",
        "src, tgt = src[:5].to(DEVICE), tgt[:5].to(DEVICE)\n",
        "print(src.shape)\n",
        "print(tgt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WI6E17_CXlfr"
      },
      "outputs": [],
      "source": [
        "logits = model(src, tgt)\n",
        "pred = torch.argmax(logits, dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtqy9lxxXlfr",
        "outputId": "a8d74e7a-89d5-4125-f908-09efff6f9637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example no 0: \n",
            "################################################################################\n",
            "#German text:  Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen\n",
            "################################################################################\n",
            "#English translation:  A group of men are loading cotton onto a truck\n",
            "################################################################################\n",
            "#Model translation:  A group of men loading loading crops ingredients a truck . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 1: \n",
            "################################################################################\n",
            "#German text:  Ein Mann schläft in einem grünen Raum auf einem Sofa .\n",
            "################################################################################\n",
            "#English translation:  A man sleeping in a green room on a couch .\n",
            "################################################################################\n",
            "#Model translation:  A man is on a green room on a couch . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 2: \n",
            "################################################################################\n",
            "#German text:  Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau .\n",
            "################################################################################\n",
            "#English translation:  A boy wearing headphones sits on a woman ' s shoulders .\n",
            "################################################################################\n",
            "#Model translation:  A boy with headphones is on a woman ' s shoulders . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 3: \n",
            "################################################################################\n",
            "#German text:  Zwei Männer bauen eine blaue Eis f ischer hütte auf einem zuge froren en See auf\n",
            "################################################################################\n",
            "#English translation:  Two men setting up a blue ice fishing hut on an iced over lake\n",
            "################################################################################\n",
            "#Model translation:  Two men building up a blue ice sculpture tent on a indoor lake lake . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 4: \n",
            "################################################################################\n",
            "#German text:  Ein Mann mit beginnender Glatze , der eine rote Rettungsweste trägt , sitzt in einem kleinen Boot .\n",
            "################################################################################\n",
            "#English translation:  A balding man wearing a red life jacket is sitting in a small boat .\n",
            "################################################################################\n",
            "#Model translation:  A bald man is a red life vest is sitting in a small boat . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for example in range(5):\n",
        "    print(f\"Example no {example}: \")\n",
        "    '''pad_count = (tgt[example] == PAD_IDX).data.sum().item()\n",
        "    sentence_len = tgt.shape[1] - pad_count'''\n",
        "    print(\"#\"*80)\n",
        "    print(\"#German text: \", tokenizer.decode(src[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"#English translation: \", tokenizer.decode(tgt[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"#Model translation: \", tokenizer.decode(pred[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taRyHEWTedXi",
        "outputId": "847423ef-62ab-4f7f-f81e-d04835368295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64])\n",
            "torch.Size([1, 64])\n"
          ]
        }
      ],
      "source": [
        "src, tgt = next(iter(test_dataloader))\n",
        "src = src[-2:-1]\n",
        "tgt = tgt[-2:-1]\n",
        "print(src.shape)\n",
        "print(tgt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPgMJ93d25w7",
        "outputId": "024956a8-cb65-427c-ca69-e739ed695e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English:  Two poodles are running through the snow .\n",
            "Model translation:  Two poodles running through the snow .\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def translate(model: nn.Module, source: Tensor, start_token: int, stop_token: int, seq_len: int):\n",
        "    model.eval()\n",
        "\n",
        "    source = source.to(DEVICE)\n",
        "    src_batch_dim = source.shape[0]\n",
        "    src_seq_len = source.shape[1]\n",
        "\n",
        "    src_mask = model.masking(src_batch_dim, src_seq_len)\n",
        "    src_pos_enc = model.positional(src_seq_len)\n",
        "    src_embedding = model.embed(source)\n",
        "\n",
        "    encoderInput = src_embedding + src_pos_enc\n",
        "\n",
        "    encoderOutput = model.encoderStack(encoderInput, src_mask)\n",
        "\n",
        "    ys = torch.tensor([[start_token]], dtype=torch.int32, device=DEVICE)\n",
        "\n",
        "    for _ in range(seq_len):\n",
        "\n",
        "        tgt_batch_dim = ys.shape[0]\n",
        "        tgt_seq_len = ys.shape[1]\n",
        "\n",
        "        embedded_sequence = model.embed(ys)\n",
        "        seq_pos_enc = model.positional(tgt_seq_len)\n",
        "        decoder_mask = model.masking(tgt_batch_dim, tgt_seq_len)\n",
        "\n",
        "        decoderInput = embedded_sequence + seq_pos_enc\n",
        "    \n",
        "        out = model.decoderStack(encoderOutput, decoderInput, decoder_mask)\n",
        "\n",
        "        logits = model.generate(out[:, -1, :])\n",
        "        generated_word_id = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        ys = torch.cat((ys, torch.tensor([[generated_word_id.item()]], \n",
        "                                                     dtype=torch.int32, device=DEVICE)), dim=1)\n",
        "\n",
        "        if generated_word_id == stop_token:\n",
        "            break\n",
        "\n",
        "    translation_ids = ys.cpu().numpy()\n",
        "\n",
        "    translation = tokenizer.decode(translation_ids.squeeze())\n",
        "    return translation\n",
        "\n",
        "translation = translate(model=model, source=src, start_token=BOS_IDX, stop_token=EOS_IDX, seq_len=MAX_LEN)\n",
        "english = tokenizer.decode(tgt.cpu().numpy().squeeze())\n",
        "print(\"English: \", english)\n",
        "print(\"Model translation: \", translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR0Q2WoxmlKJ",
        "outputId": "2bd0f622-3341-408d-db44-25877a8dd6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "German:  Ein glücklicher Hund spielt mit einem Spielzeug.\n",
            "English:  A happy dog is playing with a toy.\n",
            "Model translation:  A happy dog is playing with a toy .\n"
          ]
        }
      ],
      "source": [
        "english = \"A happy dog is playing with a toy.\"\n",
        "german = \"Ein glücklicher Hund spielt mit einem Spielzeug.\"\n",
        "encoded_german = tokenizer.encode(german)\n",
        "german_id_arr = encoded_german.ids\n",
        "\n",
        "tgt_input = torch.tensor(german_id_arr).unsqueeze(0)\n",
        "\n",
        "translation = translate(model, tgt_input, 2, 3, MAX_LEN)\n",
        "print(\"German: \", german)\n",
        "print(\"English: \", english)\n",
        "print(\"Model translation: \", translation)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6fb3815109fae185a2989dc67116c03680cdd5befd2823d06e43fcf705655cc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
