{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENcHcsQgduBi"
      },
      "outputs": [],
      "source": [
        "!pip install 'portalocker>=2.0.0'\n",
        "!pip install torch==2.0.0 torchtext==0.15.1 torchdata==0.6.0\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pWSq1ZN0MjIf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "from tokenizers import Tokenizer\n",
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M1dD0NMEMjIh"
      },
      "outputs": [],
      "source": [
        "'''Hyperparameters'''\n",
        "''' Data Parameters '''\n",
        "MAX_LEN = 64\n",
        "VOCAB_SIZE = 32768\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "BATCH_SIZE = 200\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "''' Model Parameters '''\n",
        "D_MODEL = 512\n",
        "D_H = 8\n",
        "D_FF = 2048\n",
        "EMBEDDING_SIZE = 512\n",
        "N = 3\n",
        "''' Training Parameters '''\n",
        "DROPOUT = 0.2\n",
        "LR = 0.0001\n",
        "BETAS = (0.9, 0.98)\n",
        "EPS = 1e-9\n",
        "EPOCHS = 25\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L40-TpaRYkFs"
      },
      "outputs": [],
      "source": [
        "tokenizer_path = \" \" # give the path of the pretrained tokenizer file\n",
        "\n",
        "tokenizer = Tokenizer.from_file(tokenizer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AO-nW7opMjIk"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_enc = tokenizer.encode(src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(torch.tensor(src_enc.ids))\n",
        "\n",
        "        tgt_enc = tokenizer.encode(tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_batch.append(torch.tensor(tgt_enc.ids))\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JUJ3J_o1MjIl"
      },
      "outputs": [],
      "source": [
        "train_iter = Multi30k(split='train', \n",
        "                      language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "test_iter = Multi30k(split='valid', \n",
        "                     language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vWx1lpfgaMNa"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, \n",
        "                              collate_fn=collate_fn, drop_last=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_iter, batch_size=BATCH_SIZE, \n",
        "                             collate_fn=collate_fn, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W3rOmg4YMjIl"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size=32678, embedding_size=512, pad_mask=1):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.emb = nn.Embedding(num_embeddings=vocab_size, \n",
        "                                embedding_dim=embedding_size, \n",
        "                                padding_idx=pad_mask, device=DEVICE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x) * math.sqrt(self.embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XuvYlXDuMjIm"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.d_h = d_h\n",
        "        self.d_k = d_model // d_h\n",
        "\n",
        "        self.linears = nn.ModuleList([nn.Linear(\n",
        "            d_model, self.d_k\n",
        "            ) for _ in range(d_h*3)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Linear = nn.Linear(d_model, d_model)\n",
        "        self.normalize1 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "        self.normalize2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, x_mask=None):\n",
        "        multi_head = []\n",
        "        for i in range(self.d_h):\n",
        "            query = self.linears[3*i](x)\n",
        "            key = self.linears[3*i + 1](x)\n",
        "            value = self.linears[3*i + 2](x)\n",
        "            scaledDotProd = (query @ key.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
        "            if x_mask is not None:\n",
        "                scaledDotProd = scaledDotProd.masked_fill(x_mask==0, float('-inf'))\n",
        "            soft = F.softmax(scaledDotProd, dim=-1)\n",
        "            soft = self.dropout(soft)\n",
        "            attn =  soft @ value\n",
        "            multi_head.append(attn)\n",
        "        selfAttn = self.Linear(torch.cat((multi_head), -1))\n",
        "        addNorm = self.normalize1(x + selfAttn)\n",
        "        encoderOutput = self.normalize2(x + self.feed_forward(addNorm))\n",
        "        return encoderOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cfHw7_VuMjIn"
      },
      "outputs": [],
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, \n",
        "                 dropout=0.1, N=6):\n",
        "        super(EncoderStack, self).__init__()\n",
        "\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(\n",
        "            d_model, d_ff, d_h, dropout\n",
        "            ) for _ in range(N)]) # Stacking Encoder Layer N Times\n",
        "\n",
        "    def forward(self, x, x_mask=None):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x, x_mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gaZLO3lsMjIn"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.d_h = d_h\n",
        "        self.d_k = d_model // d_h\n",
        "\n",
        "        self.linears = nn.ModuleList([nn.Linear(\n",
        "            d_model, self.d_k\n",
        "            ) for _ in range(d_h*3)])\n",
        "        \n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.firstLinear = nn.Linear(d_h * self.d_k, d_model)\n",
        "        self.normalize1 = nn.LayerNorm(d_model)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.secondLinear = nn.Linear(d_h * d_model, d_model)\n",
        "        self.normalize2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "        self.normalize3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, y, y_mask=None):\n",
        "        multi_head1 = []\n",
        "        multi_head2 = []\n",
        "\n",
        "        # FIRST ATTENTION LAYER\n",
        "        ''' Same as encoder, but here we have tgt(target) as the decoder's input '''\n",
        "        for i in range(self.d_h):\n",
        "            query = self.linears[3*i](y)\n",
        "            key = self.linears[3*i+1](y)\n",
        "            value = self.linears[3*i+2](y)\n",
        "            scaledDotProd = (query @ key.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
        "            if y_mask is not None:\n",
        "                scaledDotProd = scaledDotProd.masked_fill(y_mask==0, float('-inf'))\n",
        "            soft = F.softmax(scaledDotProd, dim=-1)\n",
        "            soft = self.dropout1(soft)\n",
        "            attn =  soft @ value\n",
        "            multi_head1.append(attn)\n",
        "        selfAttn = self.firstLinear(torch.cat((multi_head1), dim=-1))\n",
        "        addNorm1 = self.normalize1(y + selfAttn)\n",
        "\n",
        "        # SECOND ATTENTION LAYER\n",
        "        ''' Attention layer, instead of V and K matrices, we use the output of the encoder '''\n",
        "        for i in range(self.d_h):\n",
        "            scaledDotProd = (addNorm1 @ x.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
        "            soft = F.softmax(scaledDotProd, dim=-1)\n",
        "            soft = self.dropout2(soft)\n",
        "            attn = soft @ x\n",
        "            multi_head2.append(attn)\n",
        "        crossAttn = self.secondLinear(torch.cat((multi_head2), dim=-1))\n",
        "        addNorm2 = self.normalize2(y + crossAttn)\n",
        "        decoderOutput = self.normalize3(y + self.feed_forward(addNorm2))\n",
        "        return decoderOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NFSeeoKTMjIo"
      },
      "outputs": [],
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, \n",
        "                 dropout=0.1, N=6):\n",
        "        super(DecoderStack, self).__init__()\n",
        "        \n",
        "        self.decoders = nn.ModuleList([DecoderLayer(\n",
        "            d_model, d_ff, d_h, dropout\n",
        "            ) for _ in range(N)]) # Stacking Decoder Layer N Times\n",
        "\n",
        "    def forward(self, x, y, y_mask=None):\n",
        "        for decoder in self.decoders:\n",
        "            y = decoder(x, y, y_mask)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Tx4vpT4725w3"
      },
      "outputs": [],
      "source": [
        "class Mask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mask, self).__init__()\n",
        "    \n",
        "    def forward(self, batch_dim, seq_len):\n",
        "        mask = torch.ones((batch_dim,seq_len,seq_len),device=DEVICE)\n",
        "        mask = torch.tril(mask)\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P4V-2pak25w4"
      },
      "outputs": [],
      "source": [
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self, embedding_size=512, n=10000):\n",
        "        super(Positional_Encoding, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n = n\n",
        "    def forward(self, seq_len):\n",
        "        P = torch.zeros(seq_len, self.embedding_size, device=DEVICE)\n",
        "        for k in range(seq_len):\n",
        "            for i in range(self.embedding_size // 2):\n",
        "                denominator = math.pow(self.n, 2*i/self.embedding_size)\n",
        "                P[k, 2*i] = math.sin(k/denominator)\n",
        "                P[k, 2*i+1] = math.cos(k/denominator)\n",
        "        return P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Eejkpbku25wz"
      },
      "outputs": [],
      "source": [
        "class GenerateLogits(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super(GenerateLogits, self).__init__()\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lsNHTQTPMjIo"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_h = 8, d_ff=2048, \n",
        "                 embedding_size=512, vocab_size=32768, \n",
        "                 dropout=0.1, num_coder_layers=6):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embed = Embedding(vocab_size, embedding_size, pad_mask=1)\n",
        "        self.positional = Positional_Encoding(embedding_size, 10000)\n",
        "        self.masking = Mask()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.encoderStack = EncoderStack(\n",
        "            d_model, d_ff, d_h, \n",
        "            dropout, num_coder_layers)\n",
        "        \n",
        "        self.decoderStack = DecoderStack(\n",
        "            d_model, d_ff, d_h, \n",
        "            dropout, num_coder_layers)\n",
        "        \n",
        "        self.generate = GenerateLogits(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        assert x.shape[0] == y.shape[0]\n",
        "        batch_dim = x.shape[0]\n",
        "        src_seq_len, tgt_seq_len = x.shape[1], y.shape[1]\n",
        "        x_pos_encoding = self.positional(src_seq_len)\n",
        "        y_pos_encoding = self.positional(tgt_seq_len)\n",
        "        x_mask = self.masking(batch_dim, src_seq_len)\n",
        "        y_mask = self.masking(batch_dim, tgt_seq_len)\n",
        "        x, y = self.embed(x), self.embed(y)\n",
        "        x, y = x_pos_encoding + x, y_pos_encoding + y\n",
        "        x, y = self.dropout1(x), self.dropout2(y)\n",
        "        encoderOutput = self.encoderStack(x, x_mask)\n",
        "        decoderOutput = self.decoderStack(encoderOutput, y, y_mask)\n",
        "        logits = self.generate(decoderOutput)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n5c2hP21MjIp"
      },
      "outputs": [],
      "source": [
        "model = Transformer(d_model=D_MODEL, d_h=D_H, d_ff=D_FF, \n",
        "                    embedding_size=EMBEDDING_SIZE, \n",
        "                    vocab_size=VOCAB_SIZE, dropout=DROPOUT, \n",
        "                    num_coder_layers=N)\n",
        "\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z152c5EJWXYm"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "def initalize_parameters():\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4DglT1Wd8LM0"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_loss(model: nn.Module, test_data: DataLoader, \n",
        "                      padding_index: int):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=padding_index)\n",
        "    loss = []\n",
        "    for src, tgt in test_data:\n",
        "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
        "        tgt_in = tgt[:, :-1] # inputs shifted left\n",
        "        tgt_out = tgt[:, 1:] # labels shifted right\n",
        "        logits = model(src, tgt_in).permute(0, 2, 1)\n",
        "        loss.append(criterion(logits, tgt_out).item())\n",
        "    average_loss = np.average(loss)\n",
        "    model.train()\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3OfIu8IFjmbt"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, train_data: DataLoader, \n",
        "          test_data: DataLoader, learning_rate: int, \n",
        "          padding_idx: int, epoch_num: int, betas: Tuple, eps: int):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, \n",
        "                           betas=betas, eps=eps)\n",
        "    \n",
        "    epoch_test_loss = []\n",
        "    for epoch in range(epoch_num):\n",
        "        print(\"#\"*67)\n",
        "        print(f'{\"#\"*20}Training begins for epoc {epoch:>2}{\"#\"*20}')\n",
        "        print(\"#\"*67)\n",
        "        start_time = timer()\n",
        "        for _, (src, tgt) in enumerate(train_data):\n",
        "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
        "            tgt_in = tgt[:, :-1] # inputs shifted left\n",
        "            logits = model(src, tgt_in).permute(0, 2, 1)\n",
        "            optimizer.zero_grad()\n",
        "            tgt_out = tgt[:, 1:] # labels shifted right\n",
        "            loss = criterion(logits, tgt_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        end_time = timer()\n",
        "        test_loss = compute_loss(model, test_data, padding_idx)\n",
        "        str1 = f'Training is complete for epoch {epoch:>2}, '\n",
        "        str2 = f'loss = {test_loss:>5.3f}'\n",
        "        str3 = f'Time = {end_time - start_time:>3.3f}s'\n",
        "        print(str1 + str2)\n",
        "        print(str3)\n",
        "        epoch_test_loss.append(test_loss)\n",
        "        print(\"-\"*67)\n",
        "    print(\"\\n Training is complete \\n\")\n",
        "    plt.plot(epoch_test_loss, color='purple')\n",
        "    plt.title(\"Loss Graph\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1H4dfSdBLWPN",
        "outputId": "4e3c03b2-7a20-45ae-834b-a7e4fce0b538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################################################################\n",
            "####################Training begins for epoc  0####################\n",
            "###################################################################\n",
            "Training is complete for epoch  0, loss = 5.072\n",
            "Time = 366.935s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  1####################\n",
            "###################################################################\n",
            "Training is complete for epoch  1, loss = 4.240\n",
            "Time = 357.850s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  2####################\n",
            "###################################################################\n",
            "Training is complete for epoch  2, loss = 3.770\n",
            "Time = 358.304s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  3####################\n",
            "###################################################################\n",
            "Training is complete for epoch  3, loss = 3.476\n",
            "Time = 355.744s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  4####################\n",
            "###################################################################\n",
            "Training is complete for epoch  4, loss = 3.255\n",
            "Time = 357.130s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  5####################\n",
            "###################################################################\n",
            "Training is complete for epoch  5, loss = 3.052\n",
            "Time = 356.612s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  6####################\n",
            "###################################################################\n",
            "Training is complete for epoch  6, loss = 2.879\n",
            "Time = 358.288s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  7####################\n",
            "###################################################################\n",
            "Training is complete for epoch  7, loss = 2.740\n",
            "Time = 357.144s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  8####################\n",
            "###################################################################\n",
            "Training is complete for epoch  8, loss = 2.632\n",
            "Time = 356.809s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc  9####################\n",
            "###################################################################\n",
            "Training is complete for epoch  9, loss = 2.542\n",
            "Time = 356.946s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 10####################\n",
            "###################################################################\n",
            "Training is complete for epoch 10, loss = 2.463\n",
            "Time = 357.421s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 11####################\n",
            "###################################################################\n",
            "Training is complete for epoch 11, loss = 2.395\n",
            "Time = 357.275s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 12####################\n",
            "###################################################################\n",
            "Training is complete for epoch 12, loss = 2.342\n",
            "Time = 356.240s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 13####################\n",
            "###################################################################\n",
            "Training is complete for epoch 13, loss = 2.288\n",
            "Time = 356.756s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 14####################\n",
            "###################################################################\n",
            "Training is complete for epoch 14, loss = 2.265\n",
            "Time = 357.205s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 15####################\n",
            "###################################################################\n",
            "Training is complete for epoch 15, loss = 2.240\n",
            "Time = 357.625s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 16####################\n",
            "###################################################################\n",
            "Training is complete for epoch 16, loss = 2.206\n",
            "Time = 356.284s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 17####################\n",
            "###################################################################\n",
            "Training is complete for epoch 17, loss = 2.172\n",
            "Time = 358.342s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 18####################\n",
            "###################################################################\n",
            "Training is complete for epoch 18, loss = 2.162\n",
            "Time = 359.133s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 19####################\n",
            "###################################################################\n",
            "Training is complete for epoch 19, loss = 2.140\n",
            "Time = 355.873s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 20####################\n",
            "###################################################################\n",
            "Training is complete for epoch 20, loss = 2.124\n",
            "Time = 356.583s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 21####################\n",
            "###################################################################\n",
            "Training is complete for epoch 21, loss = 2.111\n",
            "Time = 354.699s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 22####################\n",
            "###################################################################\n",
            "Training is complete for epoch 22, loss = 2.115\n",
            "Time = 355.782s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 23####################\n",
            "###################################################################\n",
            "Training is complete for epoch 23, loss = 2.100\n",
            "Time = 355.077s\n",
            "-------------------------------------------------------------------\n",
            "###################################################################\n",
            "####################Training begins for epoc 24####################\n",
            "###################################################################\n",
            "Training is complete for epoch 24, loss = 2.096\n",
            "Time = 355.784s\n",
            "-------------------------------------------------------------------\n",
            "\n",
            " Training is complete \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "initalize_parameters()\n",
        "train(model, train_dataloader, test_dataloader, \n",
        "      learning_rate=LR, padding_idx=PAD_IDX, \n",
        "      epoch_num=EPOCHS, betas=BETAS, eps=EPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL1Ka42zXlfq",
        "outputId": "ea70f9c0-8362-43e7-887a-f48ac3828c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 64])\n",
            "torch.Size([5, 64])\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "src, tgt = next(iter(test_dataloader))\n",
        "src, tgt = src[:5].to(DEVICE), tgt[:5].to(DEVICE)\n",
        "print(src.shape)\n",
        "print(tgt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WI6E17_CXlfr"
      },
      "outputs": [],
      "source": [
        "logits = model(src, tgt)\n",
        "pred = torch.argmax(logits, dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtqy9lxxXlfr",
        "outputId": "8b45e88b-2314-403a-a228-e9520b9f5fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example no 0: \n",
            "################################################################################\n",
            "#German text:  Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen\n",
            "################################################################################\n",
            "#English translation:  A group of men are loading cotton onto a truck\n",
            "################################################################################\n",
            "#Model translation:  A group of men are cleaning equipment candy a truck . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 1: \n",
            "################################################################################\n",
            "#German text:  Ein Mann schläft in einem grünen Raum auf einem Sofa .\n",
            "################################################################################\n",
            "#English translation:  A man sleeping in a green room on a couch .\n",
            "################################################################################\n",
            "#Model translation:  A man sleeps on a green room on a couch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 2: \n",
            "################################################################################\n",
            "#German text:  Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau .\n",
            "################################################################################\n",
            "#English translation:  A boy wearing headphones sits on a woman ' s shoulders .\n",
            "################################################################################\n",
            "#Model translation:  A boy wearing headphones is on his woman ' s shoulders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 3: \n",
            "################################################################################\n",
            "#German text:  Zwei Männer bauen eine blaue Eis f ischer hütte auf einem zuge froren en See auf\n",
            "################################################################################\n",
            "#English translation:  Two men setting up a blue ice fishing hut on an iced over lake\n",
            "################################################################################\n",
            "#Model translation:  Two men building up a blue animal cream store on a amusement tree lake . . . . . . . . . . . . . . . . . . . . . . . . . . Two Two\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 4: \n",
            "################################################################################\n",
            "#German text:  Ein Mann mit beginnender Glatze , der eine rote Rettungsweste trägt , sitzt in einem kleinen Boot .\n",
            "################################################################################\n",
            "#English translation:  A balding man wearing a red life jacket is sitting in a small boat .\n",
            "################################################################################\n",
            "#Model translation:  A bald man is a red life jacket is sitting in a small boat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "################################################################################\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for example in range(5):\n",
        "    print(f\"Example no {example}: \")\n",
        "    '''pad_count = (tgt[example] == PAD_IDX).data.sum().item()\n",
        "    sentence_len = tgt.shape[1] - pad_count'''\n",
        "    print(\"#\"*80)\n",
        "    print(\"#German text: \", tokenizer.decode(src[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"#English translation: \", tokenizer.decode(tgt[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"#Model translation: \", tokenizer.decode(pred[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taRyHEWTedXi",
        "outputId": "cafbcafd-d5dc-4b89-c4d6-4f2b5ce79bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64])\n",
            "torch.Size([1, 64])\n"
          ]
        }
      ],
      "source": [
        "src, tgt = next(iter(test_dataloader))\n",
        "src = src[-2:-1]\n",
        "tgt = tgt[-2:-1]\n",
        "print(src.shape)\n",
        "print(tgt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPgMJ93d25w7",
        "outputId": "37046545-7f29-4e67-9f17-b4bb54b7be4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English:  A person rowing in their boat in the water .\n",
            "Model translation:  A person is rowing in her boat in the water .\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def translate(model: nn.Module, source: Tensor, start_token: int, stop_token: int, seq_len: int):\n",
        "    model.eval()\n",
        "\n",
        "    source = source.to(DEVICE)\n",
        "    src_batch_dim = source.shape[0]\n",
        "    src_seq_len = source.shape[1]\n",
        "\n",
        "    src_mask = model.masking(src_batch_dim, src_seq_len)\n",
        "    src_pos_enc = model.positional(src_seq_len)\n",
        "    src_embedding = model.embed(source)\n",
        "\n",
        "    encoderInput = src_embedding + src_pos_enc\n",
        "\n",
        "    encoderOutput = model.encoderStack(encoderInput, src_mask)\n",
        "\n",
        "    ys = torch.tensor([[start_token]], dtype=torch.int32, device=DEVICE)\n",
        "\n",
        "    for _ in range(seq_len):\n",
        "\n",
        "        tgt_batch_dim = ys.shape[0]\n",
        "        tgt_seq_len = ys.shape[1]\n",
        "\n",
        "        embedded_sequence = model.embed(ys)\n",
        "        seq_pos_enc = model.positional(tgt_seq_len)\n",
        "        decoder_mask = model.masking(tgt_batch_dim, tgt_seq_len)\n",
        "\n",
        "        decoderInput = embedded_sequence + seq_pos_enc\n",
        "    \n",
        "        out = model.decoderStack(encoderOutput, decoderInput, decoder_mask)\n",
        "\n",
        "        logits = model.generate(out[:, -1, :])\n",
        "        generated_word_id = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        ys = torch.cat((ys, torch.tensor([[generated_word_id.item()]], \n",
        "                                                     dtype=torch.int32, device=DEVICE)), dim=1)\n",
        "\n",
        "        if generated_word_id == stop_token:\n",
        "            break\n",
        "\n",
        "    translation_ids = ys.cpu().numpy()\n",
        "\n",
        "    translation = tokenizer.decode(translation_ids.squeeze())\n",
        "    return translation\n",
        "\n",
        "translation = translate(model=model, source=src, start_token=BOS_IDX, stop_token=EOS_IDX, seq_len=MAX_LEN)\n",
        "english = tokenizer.decode(tgt.cpu().numpy().squeeze())\n",
        "print(\"English: \", english)\n",
        "print(\"Model translation: \", translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR0Q2WoxmlKJ",
        "outputId": "5877e789-4282-43e3-c3bb-c2f00397ca42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "German:  Ein glücklicher Hund spielt mit einem Spielzeug.\n",
            "English:  A happy dog is playing with a toy.\n",
            "Model translation:  A happy dog is playing with a toy .\n"
          ]
        }
      ],
      "source": [
        "english = \"A happy dog is playing with a toy.\"\n",
        "german = \"Ein glücklicher Hund spielt mit einem Spielzeug.\"\n",
        "encoded_german = tokenizer.encode(german)\n",
        "german_id_arr = encoded_german.ids\n",
        "\n",
        "tgt_input = torch.tensor(german_id_arr).unsqueeze(0)\n",
        "\n",
        "translation = translate(model, tgt_input, 2, 3, MAX_LEN)\n",
        "print(\"German: \", german)\n",
        "print(\"English: \", english)\n",
        "print(\"Model translation: \", translation)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6fb3815109fae185a2989dc67116c03680cdd5befd2823d06e43fcf705655cc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
