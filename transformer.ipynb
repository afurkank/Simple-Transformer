{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWSq1ZN0MjIf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "tokenizers and torchdata need to be installed\n",
        "pip install tokenizers\n",
        "pip install torchdata\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1dD0NMEMjIh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7QQ1zDWMjIj"
      },
      "outputs": [],
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "f = open(\"parallelcorpus.txt\", \"a\")\n",
        "\n",
        "for i in train_iter:\n",
        "  for x in [x.rstrip(\"\\n\") for x in i]:\n",
        "    f.write(x)\n",
        "    f.write(' ')\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO-nW7opMjIk"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 64\n",
        "VOCAB_SIZE = 32768\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[BOS]\", \"[EOS]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "tokenizer.train(['parallelcorpus.txt'], trainer)\n",
        "\n",
        "tokenizer.enable_padding(pad_id=1, length=MAX_LEN)\n",
        "tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"[BOS] $A [EOS]\",\n",
        "    special_tokens=[\n",
        "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
        "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\")),\n",
        "    ],\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_enc = tokenizer.encode(src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(torch.tensor(src_enc.ids))\n",
        "\n",
        "        tgt_enc = tokenizer.encode(tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_batch.append(torch.tensor(tgt_enc.ids))\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUJ3J_o1MjIl"
      },
      "outputs": [],
      "source": [
        "test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size = BATCH_SIZE, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_iter, batch_size = BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3rOmg4YMjIl"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, pad_mask):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        return self.emb(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuvYlXDuMjIm"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_ff = d_ff\n",
        "        self.d_k = self.d_v = int(d_model / d_h)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Linear = nn.Linear(d_model, d_model) # Linear Layer for the concatenated head\n",
        "        self.normalize = nn.LayerNorm(d_model) # Normalizing Layer\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        heads = []\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](x) # Query Matrix\n",
        "            K = self.linears[3*i + 1](x) # Key Matrix\n",
        "            V = self.linears[3*i + 2](x) # Value Matrix\n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            head = F.softmax(scaledMatMul, dim=2) @ V # Softmax\n",
        "            heads.append(head) # A Single Head\n",
        "        Z = self.Linear(torch.cat((heads), -1)) # Concatenated heads -> Linear Layer\n",
        "        Z = self.normalize(x + self.dropout(Z)) # Output of the First Add&Norm Layer\n",
        "        Z = self.normalize(self.feed_forward(Z) + Z) # 1st Add&Norm -> Feed Forward -> 2nd Add&Norm\n",
        "        return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfHw7_VuMjIn"
      },
      "outputs": [],
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, d_h, dropout, N):\n",
        "        super(EncoderStack, self).__init__()\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Encoder Layer N Times\n",
        "\n",
        "    def forward(self, x):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaZLO3lsMjIn"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1): # parameters={}\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_k = self.d_v = int(self.d_model / self.d_h)\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)]) # linear layers\n",
        "        self.firstLinear = nn.Linear(d_h * self.d_v, d_model) # linear layer for the concatenated head\n",
        "        self.secondLinear = nn.Linear(d_h * self.d_model, d_model) # linear layer for the concatenated head(second multi-head attention)\n",
        "        self.normalize = nn.LayerNorm(d_model)\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        heads1 = []\n",
        "        heads2 = []\n",
        "\n",
        "        # FIRST ATTENTION LAYER\n",
        "        ''' Same as encoder, but here we have tgt(target) as the decoder's input '''\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](y) # Query Matrix\n",
        "            K = self.linears[3*i+1](y) # Key Matrix\n",
        "            V = self.linears[3*i+2](y) # Value Matrix\n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            maskedMat = scaledMatMul + mask # Masking\n",
        "            soft = F.softmax(maskedMat, dim=2) # Softmax\n",
        "            head =  soft @ V\n",
        "            heads1.append(head) # Appending a single head\n",
        "        Z1 = self.firstLinear(torch.cat((heads1), dim=-1)) # Concatenated heads of the First Attention Layer\n",
        "        Z1 = self.normalize(y + self.dropout(Z1)) # First Normalizing Layer\n",
        "\n",
        "        # SECOND ATTENTION LAYER\n",
        "        ''' Attention layer, instead of V and K matrices, we use the output of the encoder '''\n",
        "        for i in range(self.d_h):\n",
        "            scaledMat = Z1 @ x.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            soft = F.softmax(scaledMat, dim=2) # Softmax\n",
        "            head = soft @ x\n",
        "            heads2.append(head) # Appending a single head\n",
        "        Z2 = self.secondLinear(torch.cat((heads2), dim=-1)) # Concatenated heads of the Second Attention Layer\n",
        "        Z2 = self.normalize(Z1 + Z2) # Second Normalizing Layer\n",
        "        Z2 = self.normalize(self.feed_forward(Z2) + Z2) # Feed Forward -> Normalize\n",
        "        Z2 = self.dropout(Z2)\n",
        "        return Z2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFSeeoKTMjIo"
      },
      "outputs": [],
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, d_h, dropout, N):\n",
        "        super(DecoderStack, self).__init__()\n",
        "        self.decoders = nn.ModuleList([DecoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Decoder Layer N Times\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        for decoder in self.decoders:\n",
        "            y = decoder(x, y, mask)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsNHTQTPMjIo"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embedding_size=512, d_model=512, d_h = 8, d_ff=2048, vocab_size=32768, dropout=0.1, num_coder_layers=6):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "        self.dropoutEnc = nn.Dropout(dropout)\n",
        "        self.dropoutDec = nn.Dropout(dropout)\n",
        "        self.embed = Embedding(vocab_size, embedding_size, pad_mask=1)\n",
        "        self.encoderStack = EncoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "        self.decoderStack = DecoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "\n",
        "    def Mask(self, batch_dim):\n",
        "        size = self.d_model // self.d_h\n",
        "        mask = torch.triu(torch.tensor([[[-np.inf for _ in range(size)] for _ in range(size)] for _ in range(batch_dim)]), diagonal=1).to(device)\n",
        "        return mask\n",
        "\n",
        "    def PositionalEncoding(self, seq_len, d_model, n):\n",
        "        P = torch.zeros(seq_len, d_model)\n",
        "        for k in range(seq_len):\n",
        "            for i in range(int(d_model/2)):\n",
        "                denominator = math.pow(n, 2*i/d_model)\n",
        "                P[k, 2*i] = math.sin(k/denominator)\n",
        "                P[k, 2*i+1] = math.cos(k/denominator)\n",
        "        P = P.to(device)\n",
        "        return P\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        batch_dim = x.shape[0]\n",
        "        mask = self.Mask(batch_dim)\n",
        "        x, y = self.embed(x), self.embed(y)\n",
        "        pos_encoding = self.PositionalEncoding(self.d_model//self.d_h, self.d_model, 10000)\n",
        "        x, y = pos_encoding + x, pos_encoding + y\n",
        "        x, y = self.dropoutEnc(x), self.dropoutDec(y)\n",
        "        encoderOutput = self.encoderStack(x)\n",
        "        decoderOutput = self.decoderStack(encoderOutput, y, mask)\n",
        "        logits = self.linear(decoderOutput)\n",
        "        probs = F.log_softmax(logits, dim=-1)\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5c2hP21MjIp"
      },
      "outputs": [],
      "source": [
        "model = Transformer(embedding_size=512, d_model=512, d_h=8, d_ff=2048, vocab_size=VOCAB_SIZE, dropout=0.1, num_coder_layers=6).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OfIu8IFjmbt"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(model: nn.Module, train_data: DataLoader, test_data: DataLoader, learning_rate: int, decay_rate: int, momentum: int, padding_idx: int, epoch_num: int, max_len: int):\n",
        "\n",
        "    criterion = nn.NLLLoss(ignore_index=padding_idx)\n",
        "    \n",
        "    graph_x_loss = []\n",
        "    graph_y_loss = []\n",
        "    graph_x_acc = []\n",
        "    graph_y_acc = []\n",
        "\n",
        "    for epoch in range(1, epoch_num+1):\n",
        "\n",
        "        decayed_lr = (1 / (1 + decay_rate*(epoch-1))) * learning_rate\n",
        "        '''TODO: try Adam optimization instead of SGD''' \n",
        "        optimizer = optim.SGD(model.parameters(), lr=decayed_lr, momentum=momentum)\n",
        "\n",
        "        print(\"#\"*31)\n",
        "        print(f'##Training begins for epoc {epoch:>2}##')\n",
        "        print(\"#\"*31)\n",
        "\n",
        "        total_loss = 0\n",
        "        loss_arr = []\n",
        "\n",
        "        for i, (src, tgt) in enumerate(train_data):\n",
        "\n",
        "            if i == 10:\n",
        "                break\n",
        "\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            probs = model(src, tgt).permute(0, 2, 1)\n",
        "            loss = criterion(probs, tgt)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                loss_per_batch = total_loss / 50\n",
        "                print(f'Number of batches: {i:>4}|    Loss per batch: {loss_per_batch:>5.3f}')\n",
        "                print(\"-\"*60)\n",
        "                loss_arr.append(loss_per_batch)\n",
        "                total_loss = 0\n",
        "    \n",
        "        avg_loss = np.average(loss_arr)\n",
        "        graph_x_loss.append(epoch)\n",
        "        graph_y_loss.append(avg_loss)\n",
        "        print(f'Training is complete for epoch {epoch:>2}, average loss for epoch {epoch:>2}: {avg_loss:>5.3f}')\n",
        "        print(\"-\"*60)\n",
        "\n",
        "        acc_per_batch=0\n",
        "        test_data_size=0\n",
        "\n",
        "        for src_test, tgt_test in test_data:\n",
        "            if test_data_size==2:\n",
        "                break\n",
        "            test_data_size+=1\n",
        "            src_test, tgt_test = src_test.to(device), tgt_test.to(device)\n",
        "            probs = model(src_test, tgt_test)\n",
        "            pred = torch.argmax(probs, dim=2)\n",
        "            pred_arr = pred.cpu().numpy()\n",
        "            tgt_test_arr = tgt_test.cpu().numpy()\n",
        "            similar_idx_ratio=0\n",
        "            batch_size = tgt_test.shape[0]\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                \n",
        "                pad_idx_count = np.sum(tgt_test_arr[i] == 1)\n",
        "                sentence_len = max_len - pad_idx_count\n",
        "                similar_idx_ratio += np.sum(pred_arr[i][:sentence_len]==tgt_test_arr[i][:sentence_len]) / sentence_len\n",
        "    \n",
        "            average_similar_idx = similar_idx_ratio / batch_size\n",
        "            acc_per_batch += average_similar_idx\n",
        "    \n",
        "        total_acc = (acc_per_batch / test_data_size)*100\n",
        "        graph_x_acc.append(epoch)\n",
        "        graph_y_acc.append(total_acc)\n",
        "        print(f'Accuracy is {total_acc:>5.2f} % for epoch {epoch:>2}')\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Loss graph: \")\n",
        "    plt.plot(graph_x_loss, graph_y_loss, color='blue')\n",
        "    plt.title(\"Loss Graph\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Loss Per Epoch\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Accuracy Graph: \")\n",
        "    plt.plot(graph_x_acc, graph_y_acc, color='green')\n",
        "    plt.title(\"Accuracy Graph\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Accuracy Per Epoch\")\n",
        "    plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G4BdsVrXppFm",
        "outputId": "7349a2a0-2d32-4ca8-a986-2afb66cede82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###############################\n",
            "##Training begins for epoc  1##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 6.676\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 4.812\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 4.208\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 3.765\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 3.526\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 3.342\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 3.096\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 3.087\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 3.230\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  1, min loss for epoch  1: 3.087\n",
            "------------------------------------------------------------\n",
            "Accuracy is 70.12 % for epoch  1\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  2##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 2.741\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 2.624\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 2.566\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 2.449\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 2.411\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 2.388\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 2.270\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 2.342\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 2.531\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  2, min loss for epoch  2: 2.270\n",
            "------------------------------------------------------------\n",
            "Accuracy is 77.48 % for epoch  2\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  3##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 2.125\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 2.045\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 2.032\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.969\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.956\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.962\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.885\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.971\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 2.157\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  3, min loss for epoch  3: 1.885\n",
            "------------------------------------------------------------\n",
            "Accuracy is 81.22 % for epoch  3\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  4##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.800\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.731\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.734\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.688\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.685\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.706\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.646\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.737\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.920\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  4, min loss for epoch  4: 1.646\n",
            "------------------------------------------------------------\n",
            "Accuracy is 83.20 % for epoch  4\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  5##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.592\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.531\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.542\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.504\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.504\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.536\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.486\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.582\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.757\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  5, min loss for epoch  5: 1.486\n",
            "------------------------------------------------------------\n",
            "Accuracy is 84.55 % for epoch  5\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  6##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.449\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.394\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.411\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.374\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.382\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.413\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.370\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.462\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.634\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  6, min loss for epoch  6: 1.370\n",
            "------------------------------------------------------------\n",
            "Accuracy is 85.71 % for epoch  6\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  7##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.341\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.290\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.309\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.274\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.286\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.317\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.278\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.373\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.536\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  7, min loss for epoch  7: 1.274\n",
            "------------------------------------------------------------\n",
            "Accuracy is 86.69 % for epoch  7\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  8##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.255\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.209\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.228\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.195\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.206\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.242\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.205\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.299\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.456\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  8, min loss for epoch  8: 1.195\n",
            "------------------------------------------------------------\n",
            "Accuracy is 87.41 % for epoch  8\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc  9##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.188\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.142\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.165\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.131\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.144\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.177\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.145\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.233\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.390\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch  9, min loss for epoch  9: 1.131\n",
            "------------------------------------------------------------\n",
            "Accuracy is 88.09 % for epoch  9\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 10##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.130\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.088\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.109\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.078\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.090\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.124\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.095\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.179\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.333\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 10, min loss for epoch 10: 1.078\n",
            "------------------------------------------------------------\n",
            "Accuracy is 88.54 % for epoch 10\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 11##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.079\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.043\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.061\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 1.031\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.044\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.077\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.053\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.133\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.283\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 11, min loss for epoch 11: 1.031\n",
            "------------------------------------------------------------\n",
            "Accuracy is 89.03 % for epoch 11\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 12##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.037\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 1.003\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 1.021\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.992\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 1.006\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.037\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 1.015\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.096\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.240\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 12, min loss for epoch 12: 0.992\n",
            "------------------------------------------------------------\n",
            "Accuracy is 89.35 % for epoch 12\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 13##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 1.002\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.968\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.984\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.957\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.969\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 1.005\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.983\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.061\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.204\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 13, min loss for epoch 13: 0.957\n",
            "------------------------------------------------------------\n",
            "Accuracy is 89.85 % for epoch 13\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 14##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.970\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.939\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.954\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.926\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.943\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.974\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.953\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.028\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.170\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 14, min loss for epoch 14: 0.926\n",
            "------------------------------------------------------------\n",
            "Accuracy is 90.02 % for epoch 14\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 15##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.941\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.908\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.926\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.900\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.915\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.946\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.928\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 1.001\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.138\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 15, min loss for epoch 15: 0.900\n",
            "------------------------------------------------------------\n",
            "Accuracy is 90.20 % for epoch 15\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 16##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.914\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.886\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.899\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.875\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.890\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.923\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.904\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.975\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.113\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 16, min loss for epoch 16: 0.875\n",
            "------------------------------------------------------------\n",
            "Accuracy is 90.44 % for epoch 16\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 17##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.893\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.862\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.880\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.851\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.867\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.899\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.882\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.954\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.089\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 17, min loss for epoch 17: 0.851\n",
            "------------------------------------------------------------\n",
            "Accuracy is 90.56 % for epoch 17\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 18##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.870\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.842\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.856\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.833\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.849\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.880\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.864\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.932\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.065\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 18, min loss for epoch 18: 0.833\n",
            "------------------------------------------------------------\n",
            "Accuracy is 90.91 % for epoch 18\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 19##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.849\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.824\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.838\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.813\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.829\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.861\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.844\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.914\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.045\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 19, min loss for epoch 19: 0.813\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.06 % for epoch 19\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 20##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.832\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.806\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.822\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.796\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.812\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.844\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.828\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.895\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.023\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 20, min loss for epoch 20: 0.796\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.19 % for epoch 20\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 21##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.814\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.791\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.805\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.781\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.798\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.827\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.816\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.881\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 1.006\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 21, min loss for epoch 21: 0.781\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.38 % for epoch 21\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 22##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.802\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.775\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.789\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.765\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.783\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.815\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.800\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.863\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.989\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 22, min loss for epoch 22: 0.765\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.45 % for epoch 22\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 23##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.786\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.763\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.776\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.755\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.768\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.801\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.785\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.849\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.973\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 23, min loss for epoch 23: 0.755\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.57 % for epoch 23\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 24##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.772\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.749\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.764\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.741\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.756\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.786\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.774\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.837\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.959\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 24, min loss for epoch 24: 0.741\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.74 % for epoch 24\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 25##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.760\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.738\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.751\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.730\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.745\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.774\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.762\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.823\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.946\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 25, min loss for epoch 25: 0.730\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.89 % for epoch 25\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 26##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.748\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.726\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.740\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.719\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.733\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.762\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.752\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.813\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.932\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 26, min loss for epoch 26: 0.719\n",
            "------------------------------------------------------------\n",
            "Accuracy is 91.98 % for epoch 26\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 27##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.737\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.716\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.729\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.708\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.723\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.754\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.740\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.801\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.921\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 27, min loss for epoch 27: 0.708\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.03 % for epoch 27\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 28##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.727\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.707\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.719\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.696\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.711\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.745\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.731\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.791\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.909\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 28, min loss for epoch 28: 0.696\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.20 % for epoch 28\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 29##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.717\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.697\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.710\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.690\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.702\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.735\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.721\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.779\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.899\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 29, min loss for epoch 29: 0.690\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.31 % for epoch 29\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 30##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.708\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.688\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.700\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.680\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.695\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.725\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.713\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.771\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.888\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 30, min loss for epoch 30: 0.680\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.38 % for epoch 30\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 31##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.698\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.680\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.690\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.672\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.687\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.716\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.705\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.762\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.877\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 31, min loss for epoch 31: 0.672\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.47 % for epoch 31\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 32##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.691\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.668\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.682\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.664\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.680\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.708\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.696\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.754\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.868\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 32, min loss for epoch 32: 0.664\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.44 % for epoch 32\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 33##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.682\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.662\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.675\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.658\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.670\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.701\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.689\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.745\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.857\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 33, min loss for epoch 33: 0.658\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.54 % for epoch 33\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 34##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.674\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.655\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.668\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.650\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.664\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.694\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.682\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.738\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.850\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 34, min loss for epoch 34: 0.650\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.61 % for epoch 34\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 35##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.668\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.649\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.662\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.644\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.655\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.687\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.675\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.730\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.843\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 35, min loss for epoch 35: 0.644\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.63 % for epoch 35\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 36##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.660\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.643\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.653\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.636\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.650\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.681\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.669\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.723\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.835\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 36, min loss for epoch 36: 0.636\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.72 % for epoch 36\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 37##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.652\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.636\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.649\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.630\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.643\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.675\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.664\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.717\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.828\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 37, min loss for epoch 37: 0.630\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.87 % for epoch 37\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 38##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.647\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.629\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.643\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.623\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.637\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.667\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.657\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.710\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.821\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 38, min loss for epoch 38: 0.623\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.87 % for epoch 38\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 39##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.641\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.623\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.635\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.620\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.632\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.663\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.650\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.704\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.815\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 39, min loss for epoch 39: 0.620\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.97 % for epoch 39\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 40##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.632\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.619\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.629\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.612\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.624\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.658\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.644\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.698\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.805\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 40, min loss for epoch 40: 0.612\n",
            "------------------------------------------------------------\n",
            "Accuracy is 92.95 % for epoch 40\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 41##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.629\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.612\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.625\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.609\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.619\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.650\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.640\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.691\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.800\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 41, min loss for epoch 41: 0.609\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.08 % for epoch 41\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 42##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.622\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.608\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.620\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.602\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.614\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.646\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.636\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.685\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.793\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 42, min loss for epoch 42: 0.602\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.13 % for epoch 42\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 43##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.618\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.601\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.616\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.599\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.611\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.640\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.627\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.680\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.787\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 43, min loss for epoch 43: 0.599\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.17 % for epoch 43\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 44##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.612\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.597\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.609\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.594\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.603\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.635\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.624\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.675\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.781\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 44, min loss for epoch 44: 0.594\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.17 % for epoch 44\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 45##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.607\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.592\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.605\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.589\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.599\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.629\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.620\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.671\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.777\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 45, min loss for epoch 45: 0.589\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.21 % for epoch 45\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 46##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.602\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.588\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.600\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.585\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.595\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.625\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.614\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.666\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.771\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 46, min loss for epoch 46: 0.585\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.21 % for epoch 46\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 47##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.598\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.583\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.596\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.579\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.592\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.621\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.611\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.660\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.766\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 47, min loss for epoch 47: 0.579\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.33 % for epoch 47\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 48##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.592\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.579\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.591\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.575\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.586\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.617\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.605\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.655\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.760\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 48, min loss for epoch 48: 0.575\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.47 % for epoch 48\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 49##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.589\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.575\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.587\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.572\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.583\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.613\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.600\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.652\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.754\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 49, min loss for epoch 49: 0.572\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.45 % for epoch 49\n",
            "\n",
            "\n",
            "###############################\n",
            "##Training begins for epoc 50##\n",
            "###############################\n",
            "Number of batches:   50|    Loss per batch: 0.586\n",
            "------------------------------------------------------------\n",
            "Number of batches:  100|    Loss per batch: 0.571\n",
            "------------------------------------------------------------\n",
            "Number of batches:  150|    Loss per batch: 0.584\n",
            "------------------------------------------------------------\n",
            "Number of batches:  200|    Loss per batch: 0.569\n",
            "------------------------------------------------------------\n",
            "Number of batches:  250|    Loss per batch: 0.577\n",
            "------------------------------------------------------------\n",
            "Number of batches:  300|    Loss per batch: 0.610\n",
            "------------------------------------------------------------\n",
            "Number of batches:  350|    Loss per batch: 0.597\n",
            "------------------------------------------------------------\n",
            "Number of batches:  400|    Loss per batch: 0.646\n",
            "------------------------------------------------------------\n",
            "Number of batches:  450|    Loss per batch: 0.750\n",
            "------------------------------------------------------------\n",
            "Training is complete for epoch 50, min loss for epoch 50: 0.569\n",
            "------------------------------------------------------------\n",
            "Accuracy is 93.48 % for epoch 50\n",
            "\n",
            "\n",
            "Loss graph: \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Accuracy Graph: \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_and_eval(model, train_dataloader, test_dataloader, learning_rate=0.003, decay_rate=0.1, momentum=0.9, padding_idx=PAD_IDX, epoch_num=50, max_len=MAX_LEN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6fb3815109fae185a2989dc67116c03680cdd5befd2823d06e43fcf705655cc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
