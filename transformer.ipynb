{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata\n",
        "!pip install tokenizers"
      ],
      "metadata": {
        "id": "wlzbaFs82-lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pWSq1ZN0MjIf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1dD0NMEMjIh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l7QQ1zDWMjIj"
      },
      "outputs": [],
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "f = open(\"parallelcorpus.txt\", \"a\")\n",
        "\n",
        "for i in train_iter:\n",
        "  for x in [x.rstrip(\"\\n\") for x in i]:\n",
        "    f.write(x)\n",
        "    f.write(' ')\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AO-nW7opMjIk"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 64\n",
        "VOCAB_SIZE = 32768\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[BOS]\", \"[EOS]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "tokenizer.train(['parallelcorpus.txt'], trainer)\n",
        "\n",
        "tokenizer.enable_padding(pad_id=1, length=MAX_LEN)\n",
        "tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"[BOS] $A [EOS]\",\n",
        "    special_tokens=[\n",
        "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
        "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\")),\n",
        "    ],\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_enc = tokenizer.encode(src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(torch.tensor(src_enc.ids))\n",
        "\n",
        "        tgt_enc = tokenizer.encode(tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_batch.append(torch.tensor(tgt_enc.ids))\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JUJ3J_o1MjIl"
      },
      "outputs": [],
      "source": [
        "test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)\n",
        "test_dataloader = DataLoader(test_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W3rOmg4YMjIl"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size=32678, embedding_size=512, pad_mask=1):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        return self.emb(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Eejkpbku25wz"
      },
      "outputs": [],
      "source": [
        "class ModelOutput(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super(ModelOutput, self).__init__()\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.linear(x), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XuvYlXDuMjIm"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_ff = d_ff\n",
        "        self.d_k = self.d_v = int(d_model / d_h)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Linear = nn.Linear(d_model, d_model) # Linear Layer for the concatenated head\n",
        "        self.normalize = nn.LayerNorm(d_model) # Normalizing Layer\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        heads = []\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](x) # Query Matrix\n",
        "            K = self.linears[3*i + 1](x) # Key Matrix\n",
        "            V = self.linears[3*i + 2](x) # Value Matrix\n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            if mask is not None:\n",
        "                scaledMatMul += mask\n",
        "            head = F.softmax(scaledMatMul, dim=-1) @ V # Softmax\n",
        "            heads.append(head) # A Single Head\n",
        "        Z = self.Linear(torch.cat((heads), -1)) # Concatenated heads -> Linear Layer\n",
        "        Z = self.normalize(x + self.dropout(Z)) # Output of the First Add&Norm Layer\n",
        "        Z = self.normalize(self.feed_forward(Z) + Z) # 1st Add&Norm -> Feed Forward -> 2nd Add&Norm\n",
        "        return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cfHw7_VuMjIn"
      },
      "outputs": [],
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1, N=6):\n",
        "        super(EncoderStack, self).__init__()\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Encoder Layer N Times\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x, mask)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gaZLO3lsMjIn"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_k = self.d_v = int(self.d_model / self.d_h)\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)]) # linear layers\n",
        "        self.firstLinear = nn.Linear(d_h * self.d_v, d_model) # linear layer for the concatenated head\n",
        "        self.secondLinear = nn.Linear(d_h * self.d_model, d_model) # linear layer for the concatenated head(second multi-head attention)\n",
        "        self.normalize = nn.LayerNorm(d_model)\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, y, mask=None):\n",
        "        heads1 = []\n",
        "        heads2 = []\n",
        "\n",
        "        # FIRST ATTENTION LAYER\n",
        "        ''' Same as encoder, but here we have tgt(target) as the decoder's input '''\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](y) # Query Matrix\n",
        "            K = self.linears[3*i+1](y) # Key Matrix\n",
        "            V = self.linears[3*i+2](y) # Value Matrix\n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            if mask is not None:\n",
        "                scaledMatMul += mask\n",
        "            soft = F.softmax(scaledMatMul, dim=-1) # Softmax\n",
        "            head =  soft @ V\n",
        "            heads1.append(head) # Appending a single head\n",
        "        Z1 = self.firstLinear(torch.cat((heads1), dim=-1)) # Concatenated heads of the First Attention Layer\n",
        "        Z1 = self.normalize(y + self.dropout(Z1)) # First Normalizing Layer\n",
        "\n",
        "        # SECOND ATTENTION LAYER\n",
        "        ''' Attention layer, instead of V and K matrices, we use the output of the encoder '''\n",
        "        for i in range(self.d_h):\n",
        "            scaledMat = Z1 @ x.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            soft = F.softmax(scaledMat, dim=-1) # Softmax\n",
        "            head = soft @ x\n",
        "            heads2.append(head) # Appending a single head\n",
        "        Z2 = self.secondLinear(torch.cat((heads2), dim=-1)) # Concatenated heads of the Second Attention Layer\n",
        "        Z2 = self.normalize(Z1 + Z2) # Second Normalizing Layer\n",
        "        Z2 = self.normalize(self.feed_forward(Z2) + Z2) # Feed Forward -> Normalize\n",
        "        Z2 = self.dropout(Z2)\n",
        "        return Z2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NFSeeoKTMjIo"
      },
      "outputs": [],
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1, N=6):\n",
        "        super(DecoderStack, self).__init__()\n",
        "        self.decoders = nn.ModuleList([DecoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Decoder Layer N Times\n",
        "\n",
        "    def forward(self, x, y, mask=None):\n",
        "        for decoder in self.decoders:\n",
        "            y = decoder(x, y, mask)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Tx4vpT4725w3"
      },
      "outputs": [],
      "source": [
        "class Mask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mask, self).__init__()\n",
        "    \n",
        "    def forward(self, batch_size, seq_len):\n",
        "        mask = torch.triu(torch.tensor([[[-np.inf for _ in range(seq_len)] for _ in range(seq_len)] for _ in range(batch_size)]), diagonal=1).to(device)\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "P4V-2pak25w4"
      },
      "outputs": [],
      "source": [
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self, d_model=512, n=10000):\n",
        "        super(Positional_Encoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n = n\n",
        "    def forward(self, seq_len):\n",
        "        P = torch.zeros(seq_len, self.d_model)\n",
        "        for k in range(seq_len):\n",
        "            for i in range(self.d_model // 2):\n",
        "                denominator = math.pow(self.n, 2*i/self.d_model)\n",
        "                P[k, 2*i] = math.sin(k/denominator)\n",
        "                P[k, 2*i+1] = math.cos(k/denominator)\n",
        "        P = P.to(device)\n",
        "        return P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lsNHTQTPMjIo"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embedding_size=512, d_model=512, d_h = 8, d_ff=2048, vocab_size=32768, dropout=0.1, num_coder_layers=6):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "        self.generateProbs = ModelOutput(d_model, vocab_size)\n",
        "        self.dropoutEnc = nn.Dropout(dropout)\n",
        "        self.dropoutDec = nn.Dropout(dropout)\n",
        "        self.embed = Embedding(vocab_size, embedding_size, pad_mask=1)\n",
        "        self.positional = Positional_Encoding(self.d_model, 10000)\n",
        "        self.masking = Mask()\n",
        "        self.encoderStack = EncoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "        self.decoderStack = DecoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        batch_dim = x.shape[0]\n",
        "        seq_len = x.shape[1]\n",
        "        mask = self.masking(batch_dim, seq_len)\n",
        "        x, y = self.embed(x), self.embed(y)\n",
        "        pos_encoding = self.positional(seq_len)\n",
        "        x, y = pos_encoding + x, pos_encoding + y\n",
        "        x, y = self.dropoutEnc(x), self.dropoutDec(y)\n",
        "        encoderOutput = self.encoderStack(x)\n",
        "        decoderOutput = self.decoderStack(encoderOutput, y, mask)\n",
        "        probs = self.generateProbs(decoderOutput)\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n5c2hP21MjIp"
      },
      "outputs": [],
      "source": [
        "model = Transformer(embedding_size=512, d_model=512, d_h=8, d_ff=2048, vocab_size=VOCAB_SIZE, dropout=0.1, num_coder_layers=6).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3OfIu8IFjmbt"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(model: nn.Module, train_data: DataLoader, test_data: DataLoader, learning_rate: int, decay_rate: int, momentum: int, padding_idx: int, epoch_num: int, max_len: int):\n",
        "\n",
        "    criterion = nn.NLLLoss(ignore_index=padding_idx)\n",
        "    \n",
        "    graph_x_loss = []\n",
        "    graph_y_loss = []\n",
        "    graph_x_acc = []\n",
        "    graph_y_acc = []\n",
        "\n",
        "    for epoch in range(1, epoch_num+1):\n",
        "\n",
        "        decayed_lr = (1 / (1 + decay_rate*(epoch-1))) * learning_rate\n",
        "        '''TODO try Adam optimization instead of SGD''' \n",
        "        optimizer = optim.SGD(model.parameters(), lr=decayed_lr, momentum=momentum)\n",
        "\n",
        "        print(\"#\"*67)\n",
        "        print(f'{\"#\"*20}Training begins for epoc {epoch:>2}{\"#\"*20}')\n",
        "        print(\"#\"*67)\n",
        "\n",
        "        total_loss = 0\n",
        "        loss_arr = []\n",
        "\n",
        "        for i, (src, tgt) in enumerate(train_data):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            probs = model(src, tgt).permute(0, 2, 1)\n",
        "            loss = criterion(probs, tgt)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 450 == 0 and i != 0:\n",
        "                loss_per_batch = total_loss / 450\n",
        "                print(f'Number of batches: {i:>4}|    Loss per batch: {loss_per_batch:>5.3f}')\n",
        "                print(\"-\"*67)\n",
        "                loss_arr.append(loss_per_batch)\n",
        "                total_loss = 0\n",
        "    \n",
        "        avg_loss = np.average(loss_arr)\n",
        "        graph_x_loss.append(epoch)\n",
        "        graph_y_loss.append(avg_loss)\n",
        "        print(f'Training is complete for epoch {epoch:>2}, average loss for epoch {epoch:>2}: {avg_loss:>5.3f}')\n",
        "        print(\"-\"*67)\n",
        "\n",
        "        acc_per_batch=0\n",
        "        test_data_size=0\n",
        "\n",
        "        for src_test, tgt_test in test_data:\n",
        "            \n",
        "            test_data_size+=1\n",
        "            src_test, tgt_test = src_test.to(device), tgt_test.to(device)\n",
        "            probs = model(src_test, tgt_test)\n",
        "            pred = torch.argmax(probs, dim=2)\n",
        "            pred_arr = pred.cpu().numpy()\n",
        "            tgt_test_arr = tgt_test.cpu().numpy()\n",
        "            similar_idx_ratio=0\n",
        "            batch_size = tgt_test.shape[0]\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                \n",
        "                pad_idx_count = np.sum(tgt_test_arr[i] == 1)\n",
        "                sentence_len = max_len - pad_idx_count\n",
        "                similar_idx_ratio += np.sum(pred_arr[i][:sentence_len]==tgt_test_arr[i][:sentence_len]) / sentence_len\n",
        "    \n",
        "            average_similar_idx = similar_idx_ratio / batch_size\n",
        "            acc_per_batch += average_similar_idx\n",
        "    \n",
        "        total_acc = (acc_per_batch / test_data_size)*100\n",
        "        graph_x_acc.append(epoch)\n",
        "        graph_y_acc.append(total_acc)\n",
        "        print(f'Accuracy is {total_acc:>5.2f} % for epoch {epoch:>2}')\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Loss graph: \")\n",
        "    plt.plot(graph_x_loss, graph_y_loss, color='blue')\n",
        "    plt.title(\"Loss Graph\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Avg Loss per Epoch\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Accuracy Graph: \")\n",
        "    plt.plot(graph_x_acc, graph_y_acc, color='green')\n",
        "    plt.title(\"Accuracy Graph\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Accuracy per Epoch\")\n",
        "    plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G4BdsVrXppFm",
        "outputId": "77cefd42-122e-4b18-8e4c-fdb91ac4188d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################################################################\n",
            "####################Training begins for epoc  1####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 4.960\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 3.542\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  1, average loss for epoch  1: 4.251\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 66.52 % for epoch  1\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  2####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 2.904\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 2.694\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  2, average loss for epoch  2: 2.799\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 73.63 % for epoch  2\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  3####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 2.319\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 2.262\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  3, average loss for epoch  3: 2.290\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 78.08 % for epoch  3\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  4####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.978\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.981\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  4, average loss for epoch  4: 1.979\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 80.89 % for epoch  4\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  5####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.743\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.777\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  5, average loss for epoch  5: 1.760\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 82.77 % for epoch  5\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  6####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.570\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.620\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  6, average loss for epoch  6: 1.595\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 84.22 % for epoch  6\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  7####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.437\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.496\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  7, average loss for epoch  7: 1.467\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 85.36 % for epoch  7\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  8####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.327\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.394\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  8, average loss for epoch  8: 1.360\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 86.36 % for epoch  8\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc  9####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.238\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.306\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch  9, average loss for epoch  9: 1.272\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 87.29 % for epoch  9\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 10####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.160\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.233\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 10, average loss for epoch 10: 1.197\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 88.11 % for epoch 10\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 11####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.093\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.167\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 11, average loss for epoch 11: 1.130\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 88.63 % for epoch 11\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 12####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 1.035\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.109\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 12, average loss for epoch 12: 1.072\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 89.20 % for epoch 12\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 13####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.983\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.058\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 13, average loss for epoch 13: 1.020\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 89.65 % for epoch 13\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 14####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.936\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 1.013\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 14, average loss for epoch 14: 0.975\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 89.96 % for epoch 14\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 15####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.895\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.972\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 15, average loss for epoch 15: 0.933\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 90.42 % for epoch 15\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 16####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.859\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.933\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 16, average loss for epoch 16: 0.896\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 90.77 % for epoch 16\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 17####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.824\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.898\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 17, average loss for epoch 17: 0.861\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.19 % for epoch 17\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 18####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.794\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.868\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 18, average loss for epoch 18: 0.831\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.44 % for epoch 18\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 19####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.765\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.839\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 19, average loss for epoch 19: 0.802\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.72 % for epoch 19\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 20####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.738\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.812\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 20, average loss for epoch 20: 0.775\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.86 % for epoch 20\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 21####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.713\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.787\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 21, average loss for epoch 21: 0.750\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 92.18 % for epoch 21\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 22####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.691\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.764\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 22, average loss for epoch 22: 0.727\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 92.37 % for epoch 22\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 23####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.669\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.740\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 23, average loss for epoch 23: 0.704\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 92.63 % for epoch 23\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 24####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.649\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.720\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 24, average loss for epoch 24: 0.684\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 92.77 % for epoch 24\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 25####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.630\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.700\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 25, average loss for epoch 25: 0.665\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 92.97 % for epoch 25\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 26####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.613\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.681\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 26, average loss for epoch 26: 0.647\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.10 % for epoch 26\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 27####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.596\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.663\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 27, average loss for epoch 27: 0.630\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.33 % for epoch 27\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 28####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.580\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.647\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 28, average loss for epoch 28: 0.613\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.43 % for epoch 28\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 29####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.565\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.631\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 29, average loss for epoch 29: 0.598\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.53 % for epoch 29\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 30####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.550\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.616\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 30, average loss for epoch 30: 0.583\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.63 % for epoch 30\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 31####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.536\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.602\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 31, average loss for epoch 31: 0.569\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.76 % for epoch 31\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 32####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.524\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.588\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 32, average loss for epoch 32: 0.556\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 93.95 % for epoch 32\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 33####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.511\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.574\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 33, average loss for epoch 33: 0.542\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.02 % for epoch 33\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 34####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.499\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.560\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 34, average loss for epoch 34: 0.530\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.13 % for epoch 34\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 35####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.488\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.550\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 35, average loss for epoch 35: 0.519\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.31 % for epoch 35\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 36####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.476\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.537\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 36, average loss for epoch 36: 0.507\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.39 % for epoch 36\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 37####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.467\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.526\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 37, average loss for epoch 37: 0.496\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.47 % for epoch 37\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 38####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.456\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.515\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 38, average loss for epoch 38: 0.486\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.63 % for epoch 38\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 39####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.446\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.505\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 39, average loss for epoch 39: 0.475\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.80 % for epoch 39\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 40####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.438\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.494\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 40, average loss for epoch 40: 0.466\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.83 % for epoch 40\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 41####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.428\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.484\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 41, average loss for epoch 41: 0.456\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 94.97 % for epoch 41\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 42####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.420\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.475\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 42, average loss for epoch 42: 0.447\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.08 % for epoch 42\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 43####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.412\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.465\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 43, average loss for epoch 43: 0.439\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.10 % for epoch 43\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 44####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.403\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.457\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 44, average loss for epoch 44: 0.430\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.07 % for epoch 44\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 45####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.395\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.448\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 45, average loss for epoch 45: 0.422\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.21 % for epoch 45\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 46####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.388\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.440\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 46, average loss for epoch 46: 0.414\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.27 % for epoch 46\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 47####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.380\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.432\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 47, average loss for epoch 47: 0.406\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.32 % for epoch 47\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 48####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.374\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.424\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 48, average loss for epoch 48: 0.399\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.44 % for epoch 48\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 49####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.367\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.417\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 49, average loss for epoch 49: 0.392\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.49 % for epoch 49\n",
            "\n",
            "\n",
            "###################################################################\n",
            "####################Training begins for epoc 50####################\n",
            "###################################################################\n",
            "Number of batches:  450|    Loss per batch: 0.361\n",
            "-------------------------------------------------------------------\n",
            "Number of batches:  900|    Loss per batch: 0.409\n",
            "-------------------------------------------------------------------\n",
            "Training is complete for epoch 50, average loss for epoch 50: 0.385\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 95.58 % for epoch 50\n",
            "\n",
            "\n",
            "Loss graph: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy Graph: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_and_eval(model, train_dataloader, test_dataloader, learning_rate=0.001, decay_rate=0, momentum=0.9, padding_idx=PAD_IDX, epoch_num=50, max_len=MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H0SZ-xLHMjIr"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"transformerBatch32Epoc50LR0001.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"transformerEntireModel.pth\")"
      ],
      "metadata": {
        "id": "4Y75KDxjhDf1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YPgMJ93d25w7"
      },
      "outputs": [],
      "source": [
        "def translate(model: nn.Module, source: Tensor, start_token: int, stop_token: int, seq_len: int):\n",
        "    batch_dim = source.shape[0]\n",
        "    src_mask = model.masking(batch_dim)\n",
        "    src_pos_enc = model.positional(seq_len)\n",
        "    encoderInput = model.embed(source) + src_pos_enc\n",
        "\n",
        "    encoderOutput = model.encoderStack(encoderInput, src_mask)\n",
        "\n",
        "    sequence = torch.tensor([[start_token]], dtype=torch.int32, device=device)\n",
        "    \n",
        "    for _ in range(1, seq_len):\n",
        "        \n",
        "        embedded_sequence = model.embed(sequence)\n",
        "        seq_pos_enc = model.positional(sequence.shape[1])\n",
        "        decoderInput = embedded_sequence + seq_pos_enc\n",
        "\n",
        "        decoderOutput = model.decoderStack(encoderOutput, decoderInput) # decoderOutput.shape = [ batch_dim, # of all generated words, embedding_size ]\n",
        "\n",
        "        raw_word = decoderOutput[:, -1, :] # raw_word.shape = [ batch_dim, embed_size ]\n",
        "\n",
        "        probs = model.generateProbs(raw_word) # probs.shape = [ batch_dim, vocab_size ]\n",
        "\n",
        "        _, generated_word_id = torch.max(probs, dim=1)\n",
        "\n",
        "        generated_word_tensor = torch.tensor([[generated_word_id]], dtype=torch.int32, device=device)\n",
        "\n",
        "        sequence = torch.cat((sequence, generated_word_tensor), dim=1)\n",
        "\n",
        "        if generated_word_id == stop_token:\n",
        "            break\n",
        "\n",
        "    translation_ids = sequence.cpu().numpy()\n",
        "\n",
        "    translation = tokenizer.decode(translation_ids.squeeze())\n",
        "\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au_0waIyllF0"
      },
      "outputs": [],
      "source": [
        "src, _ = next(iter(test_dataloader))\n",
        "src = src[:1]\n",
        "print(src.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNge8nh625w8"
      },
      "outputs": [],
      "source": [
        "translation = translate(model=model, source=src, start_token=BOS_IDX, stop_token=EOS_IDX, seq_len=MAX_LEN)\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR0Q2WoxmlKJ"
      },
      "outputs": [],
      "source": [
        "encoded_german = tokenizer.encode(\"Auf der Veranda spielt ein glücklicher Hund.\")\n",
        "german_id_arr = encoded_german.ids\n",
        "\n",
        "german = torch.tensor(german_id_arr).unsqueeze(0)\n",
        "print(german)\n",
        "print(german.shape)\n",
        "\n",
        "translation = translate(model, german, 2, 3, MAX_LEN)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6fb3815109fae185a2989dc67116c03680cdd5befd2823d06e43fcf705655cc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}