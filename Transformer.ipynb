{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWSq1ZN0MjIf",
        "outputId": "093604a1-3405-4978-9c22-44317a8a25fe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "!pip install tokenizers\n",
        "!pip install torchdata\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1dD0NMEMjIh",
        "outputId": "31187c42-b9c6-4656-cb72-657c2922ccfd"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l7QQ1zDWMjIj"
      },
      "outputs": [],
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\n",
        "f = open(\"parallelcorpus.txt\", \"a\")\n",
        "\n",
        "for i in train_iter:\n",
        "  for x in [x.rstrip(\"\\n\") for x in i]:\n",
        "    f.write(x)\n",
        "    f.write(' ')\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AO-nW7opMjIk"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 64\n",
        "VOCAB_SIZE = 32768\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[BOS]\", \"[EOS]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "tokenizer.train(['parallelcorpus.txt'], trainer)\n",
        "\n",
        "tokenizer.enable_padding(pad_id=1, length=MAX_LEN)\n",
        "tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"[BOS] $A [EOS]\",\n",
        "    special_tokens=[\n",
        "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
        "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\")),\n",
        "    ],\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_enc = tokenizer.encode(src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(torch.tensor(src_enc.ids))\n",
        "\n",
        "        tgt_enc = tokenizer.encode(tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_batch.append(torch.tensor(tgt_enc.ids))\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JUJ3J_o1MjIl"
      },
      "outputs": [],
      "source": [
        "test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)\n",
        "test_dataloader = DataLoader(test_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W3rOmg4YMjIl"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size=32678, d_model=512, pad_mask=1):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model, padding_idx=pad_mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XuvYlXDuMjIm"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_ff = d_ff\n",
        "        self.d_k = self.d_v = int(d_model / d_h)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Linear = nn.Linear(d_model, d_model) # Linear Layer for the concatenated head\n",
        "        self.normalize = nn.LayerNorm(d_model) # Normalizing Layer\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        heads = []\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](x) # Query Matrix\n",
        "            K = self.linears[3*i + 1](x) # Key Matrix\n",
        "            V = self.linears[3*i + 2](x) # Value Matrix\n",
        "            scaledMatMul = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            soft = F.softmax(scaledMatMul, dim=-1)\n",
        "            soft = self.dropout(soft)\n",
        "            head =  soft @ V # Softmax\n",
        "            heads.append(head) # A Single Head\n",
        "        Z = self.Linear(torch.cat((heads), -1)) # Concatenated heads -> Linear Layer\n",
        "        Z = self.normalize(x + Z) # Output of the First Add&Norm Layer\n",
        "        Z = self.normalize(self.feed_forward(Z) + Z) # 1st Add&Norm -> Feed Forward -> 2nd Add&Norm\n",
        "        return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cfHw7_VuMjIn"
      },
      "outputs": [],
      "source": [
        "class EncoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1, N=6):\n",
        "        super(EncoderStack, self).__init__()\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Encoder Layer N Times\n",
        "\n",
        "    def forward(self, x):\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gaZLO3lsMjIn"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.d_k = self.d_v = int(self.d_model / self.d_h)\n",
        "        self.linears = nn.ModuleList([nn.Linear(d_model, self.d_k) for _ in range(d_h*3)]) # linear layers\n",
        "        self.firstLinear = nn.Linear(d_h * self.d_v, d_model) # linear layer for the concatenated head\n",
        "        self.secondLinear = nn.Linear(d_h * self.d_model, d_model) # linear layer for the concatenated head(second multi-head attention)\n",
        "        self.normalize = nn.LayerNorm(d_model)\n",
        "        self.feed_forward = nn.Sequential( # Feed Forward Layer\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, y, y_mask=None):\n",
        "        heads1 = []\n",
        "        heads2 = []\n",
        "\n",
        "        # FIRST ATTENTION LAYER\n",
        "        ''' Same as encoder, but here we have tgt(target) as the decoder's input '''\n",
        "        for i in range(self.d_h):\n",
        "            Q = self.linears[3*i](y) # Query Matrix\n",
        "            K = self.linears[3*i+1](y) # Key Matrix\n",
        "            V = self.linears[3*i+2](y) # Value Matrix\n",
        "            scaledMat = Q @ K.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and K.T -> Scale\n",
        "            if y_mask is not None:\n",
        "                scaledMat = scaledMat.masked_fill(y_mask==0, -1e9)\n",
        "            soft = F.softmax(scaledMat, dim=-1) # Softmax\n",
        "            soft = self.dropout1(soft)\n",
        "            head =  soft @ V\n",
        "            heads1.append(head) # Appending a single head\n",
        "        Z1 = self.firstLinear(torch.cat((heads1), dim=-1)) # Concatenated heads of the First Attention Layer\n",
        "        Z1 = self.normalize(y + Z1) # First Normalizing Layer\n",
        "\n",
        "        # SECOND ATTENTION LAYER\n",
        "        ''' Attention layer, instead of V and K matrices, we use the output of the encoder '''\n",
        "        for i in range(self.d_h):\n",
        "            scaledMat = Z1 @ x.transpose(-1, -2) / math.sqrt(self.d_k) # Matrix mul. of Q and encoderOutput.T -> Scale\n",
        "            soft = F.softmax(scaledMat, dim=-1) # Softmax\n",
        "            soft = self.dropout2(soft)\n",
        "            head = soft @ x\n",
        "            heads2.append(head) # Appending a single head\n",
        "        Z2 = self.secondLinear(torch.cat((heads2), dim=-1)) # Concatenated heads of the Second Attention Layer\n",
        "        Z2 = self.normalize(Z1 + Z2) # Second Normalizing Layer\n",
        "        Z2 = self.normalize(self.feed_forward(Z2) + Z2) # Feed Forward -> Normalize\n",
        "        return Z2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NFSeeoKTMjIo"
      },
      "outputs": [],
      "source": [
        "class DecoderStack(nn.Module):\n",
        "    def __init__(self, d_model=512, d_ff=2048, d_h=8, dropout=0.1, N=6):\n",
        "        super(DecoderStack, self).__init__()\n",
        "        self.decoders = nn.ModuleList([DecoderLayer(d_model, d_ff, d_h, dropout) for _ in range(N)]) # Stacking Decoder Layer N Times\n",
        "\n",
        "    def forward(self, x, y, y_mask):\n",
        "        for decoder in self.decoders:\n",
        "            y = decoder(x, y, y_mask)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tx4vpT4725w3"
      },
      "outputs": [],
      "source": [
        "class Mask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mask, self).__init__()\n",
        "    \n",
        "    def forward(self, batch_size, seq_len1, seq_len2):\n",
        "        mask = (torch.triu(torch.ones((batch_size, seq_len1, seq_len2), dtype=torch.int32), diagonal=1) == 0)\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P4V-2pak25w4"
      },
      "outputs": [],
      "source": [
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self, d_model=512, n=10000):\n",
        "        super(Positional_Encoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n = n\n",
        "    def forward(self, seq_len):\n",
        "        P = torch.zeros(seq_len, self.d_model)\n",
        "        for k in range(seq_len):\n",
        "            for i in range(self.d_model // 2):\n",
        "                denominator = math.pow(self.n, 2*i/self.d_model)\n",
        "                P[k, 2*i] = math.sin(k/denominator)\n",
        "                P[k, 2*i+1] = math.cos(k/denominator)\n",
        "        return P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Eejkpbku25wz"
      },
      "outputs": [],
      "source": [
        "class ModelOutput(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super(ModelOutput, self).__init__()\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.linear(x), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lsNHTQTPMjIo"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model=512, d_h = 8, d_ff=2048, vocab_size=32768, dropout=0.1, num_coder_layers=6):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_h = d_h\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "        self.generateProbs = ModelOutput(d_model, vocab_size)\n",
        "        self.dropoutEnc = nn.Dropout(dropout)\n",
        "        self.dropoutDec = nn.Dropout(dropout)\n",
        "        self.embed = Embedding(vocab_size, d_model, pad_mask=1)\n",
        "        self.positional = Positional_Encoding(self.d_model, 10000)\n",
        "        self.masking = Mask()\n",
        "        self.encoderStack = EncoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "        self.decoderStack = DecoderStack(d_model, d_ff, d_h, dropout, num_coder_layers)\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        assert x.shape[0] == y.shape[0]\n",
        "        batch_dim = x.shape[0]\n",
        "        assert x.shape[1] == y.shape[1]\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        y_mask = self.masking(batch_dim, seq_len, seq_len)\n",
        "\n",
        "        x, y = self.embed(x), self.embed(y)\n",
        "\n",
        "        pos_encoding = self.positional(seq_len)\n",
        "\n",
        "        x = pos_encoding + x\n",
        "        y = pos_encoding + y\n",
        "\n",
        "        x, y = self.dropoutEnc(x), self.dropoutDec(y)\n",
        "\n",
        "        encoderOutput = self.encoderStack(x)\n",
        "\n",
        "        decoderOutput = self.decoderStack(encoderOutput, y, y_mask)\n",
        "\n",
        "        probs = self.generateProbs(decoderOutput)\n",
        "\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n5c2hP21MjIp"
      },
      "outputs": [],
      "source": [
        "model = Transformer(d_model=512, d_h=8, d_ff=2048, vocab_size=VOCAB_SIZE, dropout=0.3, num_coder_layers=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3OfIu8IFjmbt",
        "outputId": "a8e3c56a-2ec1-4c47-befb-140700e968a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################################################################\n",
            "####################Training begins for epoc  1####################\n",
            "###################################################################\n",
            "Training is complete for epoch  1, average loss for epoch  1: 4.290\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 66.75 % for epoch  1\n",
            "###################################################################\n",
            "####################Training begins for epoc  2####################\n",
            "###################################################################\n",
            "Training is complete for epoch  2, average loss for epoch  2: 2.809\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 74.43 % for epoch  2\n",
            "###################################################################\n",
            "####################Training begins for epoc  3####################\n",
            "###################################################################\n",
            "Training is complete for epoch  3, average loss for epoch  3: 2.296\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 78.79 % for epoch  3\n",
            "###################################################################\n",
            "####################Training begins for epoc  4####################\n",
            "###################################################################\n",
            "Training is complete for epoch  4, average loss for epoch  4: 1.985\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 81.49 % for epoch  4\n",
            "###################################################################\n",
            "####################Training begins for epoc  5####################\n",
            "###################################################################\n",
            "Training is complete for epoch  5, average loss for epoch  5: 1.771\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 83.08 % for epoch  5\n",
            "###################################################################\n",
            "####################Training begins for epoc  6####################\n",
            "###################################################################\n",
            "Training is complete for epoch  6, average loss for epoch  6: 1.610\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 84.32 % for epoch  6\n",
            "###################################################################\n",
            "####################Training begins for epoc  7####################\n",
            "###################################################################\n",
            "Training is complete for epoch  7, average loss for epoch  7: 1.485\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 85.41 % for epoch  7\n",
            "###################################################################\n",
            "####################Training begins for epoc  8####################\n",
            "###################################################################\n",
            "Training is complete for epoch  8, average loss for epoch  8: 1.383\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 86.31 % for epoch  8\n",
            "###################################################################\n",
            "####################Training begins for epoc  9####################\n",
            "###################################################################\n",
            "Training is complete for epoch  9, average loss for epoch  9: 1.295\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 87.31 % for epoch  9\n",
            "###################################################################\n",
            "####################Training begins for epoc 10####################\n",
            "###################################################################\n",
            "Training is complete for epoch 10, average loss for epoch 10: 1.220\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 88.09 % for epoch 10\n",
            "###################################################################\n",
            "####################Training begins for epoc 11####################\n",
            "###################################################################\n",
            "Training is complete for epoch 11, average loss for epoch 11: 1.153\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 88.67 % for epoch 11\n",
            "###################################################################\n",
            "####################Training begins for epoc 12####################\n",
            "###################################################################\n",
            "Training is complete for epoch 12, average loss for epoch 12: 1.095\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 89.21 % for epoch 12\n",
            "###################################################################\n",
            "####################Training begins for epoc 13####################\n",
            "###################################################################\n",
            "Training is complete for epoch 13, average loss for epoch 13: 1.043\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 89.68 % for epoch 13\n",
            "###################################################################\n",
            "####################Training begins for epoc 14####################\n",
            "###################################################################\n",
            "Training is complete for epoch 14, average loss for epoch 14: 0.996\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 90.14 % for epoch 14\n",
            "###################################################################\n",
            "####################Training begins for epoc 15####################\n",
            "###################################################################\n",
            "Training is complete for epoch 15, average loss for epoch 15: 0.953\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 90.49 % for epoch 15\n",
            "###################################################################\n",
            "####################Training begins for epoc 16####################\n",
            "###################################################################\n",
            "Training is complete for epoch 16, average loss for epoch 16: 0.915\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 90.86 % for epoch 16\n",
            "###################################################################\n",
            "####################Training begins for epoc 17####################\n",
            "###################################################################\n",
            "Training is complete for epoch 17, average loss for epoch 17: 0.880\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.09 % for epoch 17\n",
            "###################################################################\n",
            "####################Training begins for epoc 18####################\n",
            "###################################################################\n",
            "Training is complete for epoch 18, average loss for epoch 18: 0.848\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.45 % for epoch 18\n",
            "###################################################################\n",
            "####################Training begins for epoc 19####################\n",
            "###################################################################\n",
            "Training is complete for epoch 19, average loss for epoch 19: 0.818\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.72 % for epoch 19\n",
            "###################################################################\n",
            "####################Training begins for epoc 20####################\n",
            "###################################################################\n",
            "Training is complete for epoch 20, average loss for epoch 20: 0.791\n",
            "-------------------------------------------------------------------\n",
            "Accuracy is 91.93 % for epoch 20\n",
            "Loss graph: \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Accuracy Graph: \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def train_and_eval(model: nn.Module, train_data: DataLoader, test_data: DataLoader, learning_rate: int, padding_idx: int, epoch_num: int):\n",
        "\n",
        "    criterion = nn.NLLLoss(ignore_index=padding_idx)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    graph_x_loss = []\n",
        "    graph_y_loss = []\n",
        "    graph_x_acc = []\n",
        "    graph_y_acc = []\n",
        "\n",
        "    for epoch in range(1, epoch_num+1):\n",
        "\n",
        "        print(\"#\"*67)\n",
        "        print(f'{\"#\"*20}Training begins for epoc {epoch:>2}{\"#\"*20}')\n",
        "        print(\"#\"*67)\n",
        "\n",
        "        loss_arr = []\n",
        "        for i, (src, tgt) in enumerate(train_data):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            probs = model(src, tgt).permute(0, 2, 1)\n",
        "            loss = criterion(probs, tgt)\n",
        "            loss_arr.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        avg_loss = np.average(loss_arr)\n",
        "        graph_x_loss.append(epoch)\n",
        "        graph_y_loss.append(avg_loss)\n",
        "        print(f'Training is complete for epoch {epoch:>2}, average loss for epoch {epoch:>2}: {avg_loss:>5.3f}')\n",
        "        print(\"-\"*67)\n",
        "\n",
        "        acc_per_batch=0\n",
        "        test_data_size=0\n",
        "        for src_test, tgt_test in test_data:\n",
        "            test_data_size+=1\n",
        "            src_test, tgt_test = src_test.to(device), tgt_test.to(device)\n",
        "            probs = model(src_test, tgt_test)\n",
        "            pred = torch.argmax(probs, dim=2)\n",
        "            pred_arr = pred.cpu().numpy()\n",
        "            tgt_test_arr = tgt_test.cpu().numpy()\n",
        "            similar_idx_ratio=0\n",
        "            batch_size = tgt_test.shape[0]\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                    \n",
        "                pad_idx_count = np.sum(tgt_test_arr[i] == 1)\n",
        "                sentence_len = tgt.shape[1] - pad_idx_count\n",
        "                similar_idx_ratio += np.sum(pred_arr[i][:sentence_len]==tgt_test_arr[i][:sentence_len]) / sentence_len\n",
        "        \n",
        "            average_similar_idx = similar_idx_ratio / batch_size\n",
        "            acc_per_batch += average_similar_idx\n",
        "    \n",
        "        total_acc = (acc_per_batch / test_data_size)*100\n",
        "        graph_x_acc.append(epoch)\n",
        "        graph_y_acc.append(total_acc)\n",
        "        print(f'Accuracy is {total_acc:>5.2f} % for epoch {epoch:>2}')\n",
        "    \n",
        "    print(\"Loss graph: \")\n",
        "    plt.plot(graph_x_loss, graph_y_loss, color='blue')\n",
        "    plt.title(\"Loss Graph\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Avg Loss per Epoch\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Accuracy Graph: \")\n",
        "    plt.plot(graph_x_acc, graph_y_acc, color='green')\n",
        "    plt.title(\"Accuracy Graph\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Accuracy per Epoch\")\n",
        "    plt.show\n",
        "\n",
        "\n",
        "\n",
        "train_and_eval(model, train_dataloader, test_dataloader, learning_rate=0.001, padding_idx=PAD_IDX, epoch_num=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hvc3_CKWi5hJ"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"modelparams.pth\")\n",
        "torch.save(model, \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iivYZU-Zh_R",
        "outputId": "6fffa1e1-4184-435d-a5c8-223c7f17784b"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(map_location=torch.device('cpu'), f=\"modelparams.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL1Ka42zXlfq",
        "outputId": "ed6ed1d6-e93b-4c22-f132-54220da09454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 64])\n",
            "torch.Size([32, 64])\n"
          ]
        }
      ],
      "source": [
        "src, tgt = next(iter(test_dataloader))\n",
        "print(src.shape)\n",
        "print(tgt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI6E17_CXlfr"
      },
      "outputs": [],
      "source": [
        "logits = model(src, tgt)\n",
        "pred = torch.argmax(logits, dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtqy9lxxXlfr",
        "outputId": "60a40bd4-0137-4b2b-bda1-426dd7d53980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example no 0: \n",
            "################################################################################\n",
            "#German text:  Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen\n",
            "################################################################################\n",
            "#English translation:  A group of men are loading cotton onto a truck\n",
            "################################################################################\n",
            "#Model translation:  A group of men are game ladder onto a truck\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 1: \n",
            "################################################################################\n",
            "#German text:  Ein Mann schläft in einem grünen Raum auf einem Sofa .\n",
            "################################################################################\n",
            "#English translation:  A man sleeping in a green room on a couch .\n",
            "################################################################################\n",
            "#Model translation:  A man sleeping in a green room on a couch .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 2: \n",
            "################################################################################\n",
            "#German text:  Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau .\n",
            "################################################################################\n",
            "#English translation:  A boy wearing headphones sits on a woman ' s shoulders .\n",
            "################################################################################\n",
            "#Model translation:  A boy wearing headphones sits on a woman ' s shoulders .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 3: \n",
            "################################################################################\n",
            "#German text:  Zwei Männer bauen eine blaue Eis f ischer hütte auf einem zuge froren en See auf\n",
            "################################################################################\n",
            "#English translation:  Two men setting up a blue ice fishing hut on an iced over lake\n",
            "################################################################################\n",
            "#Model translation:  Two men setting up a blue ice fishing table on an race over lake\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 4: \n",
            "################################################################################\n",
            "#German text:  Ein Mann mit beginnender Glatze , der eine rote Rettungsweste trägt , sitzt in einem kleinen Boot .\n",
            "################################################################################\n",
            "#English translation:  A balding man wearing a red life jacket is sitting in a small boat .\n",
            "################################################################################\n",
            "#Model translation:  A balding man wearing a red life jacket is sitting in a small boat .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 5: \n",
            "################################################################################\n",
            "#German text:  Eine Frau in einem rotem Mantel , die eine vermutlich aus Asien st ammen de Handtasche in einem blauen Farbton hält , springt für einen Schnappschuss in die Luft .\n",
            "################################################################################\n",
            "#English translation:  A lady in a red coat , holding a blu ish hand bag likely of asian descent , jumping off the ground for a snap shot .\n",
            "################################################################################\n",
            "#Model translation:  A lady in a red coat , holding a bags plays hand bag shorts of asian phone , jumping off the ground for a and shot .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 6: \n",
            "################################################################################\n",
            "#German text:  Ein brauner Hund rennt dem schwarzen Hund hinterher .\n",
            "################################################################################\n",
            "#English translation:  A brown dog is running after the black dog .\n",
            "################################################################################\n",
            "#Model translation:  A brown dog is running after the black dog .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 7: \n",
            "################################################################################\n",
            "#German text:  Ein kleiner Junge mit einem Giants - Trikot schwingt einen Baseballschläger in Richtung eines ankommenden Balls .\n",
            "################################################################################\n",
            "#English translation:  A young boy wearing a Giants jersey swings a baseball bat at an incoming pitch .\n",
            "################################################################################\n",
            "#Model translation:  A young boy wearing a against jersey swings a baseball bat at an her pitch .\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 8: \n",
            "################################################################################\n",
            "#German text:  Ein Mann telefoniert in einem unaufgeräumten Büro\n",
            "################################################################################\n",
            "#English translation:  A man in a cluttered office is using the telephone\n",
            "################################################################################\n",
            "#Model translation:  A man in a outside office is using the of\n",
            "################################################################################\n",
            "\n",
            "\n",
            "Example no 9: \n",
            "################################################################################\n",
            "#German text:  Eine lächelnde Frau mit einem pfirsichfarbenen Trägershirt hält ein Mountainbike\n",
            "################################################################################\n",
            "#English translation:  A smiling woman in a peach tank top stands holding a mountain bike\n",
            "################################################################################\n",
            "#Model translation:  A smiling woman in a parade tank top stands holding a mountain bike\n",
            "################################################################################\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for example in range(10):\n",
        "    print(f\"Example no {example}: \")\n",
        "    pad_count = (tgt[example] == PAD_IDX).data.sum().item()\n",
        "    sentence_len = tgt.shape[1] - pad_count\n",
        "    print(\"#\"*80)\n",
        "    print(\"#German text: \", tokenizer.decode(src[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"#English translation: \", tokenizer.decode(tgt[example].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"#Model translation: \", tokenizer.decode(pred[example][:sentence_len].cpu().numpy().squeeze()))\n",
        "    print(\"#\"*80)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au_0waIyllF0",
        "outputId": "92a159fd-d13f-4671-f33c-dde411576384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64])\n"
          ]
        }
      ],
      "source": [
        "src, _ = next(iter(test_dataloader))\n",
        "src = src[:1]\n",
        "print(src.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPgMJ93d25w7",
        "outputId": "74267562-126e-4e88-9d62-9da8f84533ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 512])\n",
            "tensor([[[ 0.6023,  2.9939,  0.7936,  ..., -1.1592,  0.5735,  1.0952],\n",
            "         [ 0.2030,  2.1087, -0.8055,  ..., -1.2593, -0.3812,  0.3840],\n",
            "         [ 0.0060,  1.4875, -1.1197,  ..., -0.3020, -0.0506, -0.5647],\n",
            "         ...,\n",
            "         [-0.4691,  0.8628, -1.8266,  ..., -0.3426, -0.8681,  0.1060],\n",
            "         [-0.4564,  0.7784, -1.8040,  ..., -0.2701, -0.8272,  0.2649],\n",
            "         [-0.4346,  0.7782, -1.7637,  ..., -0.2142, -0.7127,  0.3019]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "torch.Size([1, 1])\n",
            "tensor([[2]], dtype=torch.int32)\n",
            "torch.Size([1, 1, 512])\n",
            "torch.Size([1, 1, 512])\n",
            "torch.Size([1, 1, 512])\n",
            "tensor([[[-1.0620e+01,  2.1901e+01,  4.8903e+01,  2.6261e+01,  3.4013e+01,\n",
            "          -1.1546e+01, -5.0398e+00, -5.5647e+00,  1.1452e+01, -3.0138e+01,\n",
            "           1.6622e+01,  1.5119e+01,  9.6168e+00,  1.2807e+01, -8.9522e+00,\n",
            "           2.2811e+00,  1.3801e+01,  2.7980e+01,  1.3840e+01, -4.0438e+01,\n",
            "          -1.5522e+01, -1.1496e+01,  1.5938e+01,  2.7592e+01, -4.0819e+00,\n",
            "           4.9961e+00,  8.0287e+00,  1.5039e+01, -1.2988e+01,  4.6420e+01,\n",
            "           2.4124e+01, -3.9039e+01,  7.3013e+00, -2.1411e+01, -6.4544e-01,\n",
            "           1.9154e+01, -2.9172e+01,  4.6876e+01,  9.5456e+00,  5.4464e+01,\n",
            "          -1.1586e+01, -1.5352e+01,  9.1789e+00,  1.1394e+01, -1.1391e+01,\n",
            "          -4.4404e+00,  1.3445e+01,  1.8605e+01, -5.2610e+00,  7.0708e+00,\n",
            "          -4.7168e+01, -2.0185e-01,  1.6492e+01,  6.5306e+00,  4.8067e+01,\n",
            "          -1.5629e+01,  1.6738e+01,  3.6814e+01,  5.7833e+00,  4.2179e+00,\n",
            "           1.2478e+01, -4.4975e+00, -2.3792e+01, -1.6656e+01, -1.8063e+01,\n",
            "           1.3756e+01, -5.7748e+00,  1.8049e+01, -1.0415e+01, -3.2776e+00,\n",
            "          -1.0070e+01, -1.0833e+01,  2.6889e+00, -1.2195e+01, -1.4200e+01,\n",
            "          -1.8333e-01,  1.9120e+01,  3.9204e+00, -8.1721e+00,  1.5157e+01,\n",
            "           1.7567e+01, -1.9141e+01,  6.9286e+00,  3.7684e+00, -2.5494e+00,\n",
            "          -1.2790e+01, -9.7310e+00, -3.8151e+01,  6.4438e+00, -1.8935e+01,\n",
            "          -2.3335e+01,  3.1514e+01, -8.2791e-01,  7.6457e+00, -8.7787e+00,\n",
            "          -9.4605e+00, -2.2490e+01,  6.1022e+01,  4.1361e+01,  4.2338e+00,\n",
            "           1.6275e+00,  2.9331e+01, -3.7901e+01,  3.7419e+00, -1.6043e+01,\n",
            "           4.0532e+01, -3.7662e-01,  1.9230e+01, -1.6904e+01,  1.7564e+01,\n",
            "           2.3848e+01, -1.6058e+01,  1.7045e+01, -8.5616e+00,  7.6693e+00,\n",
            "           1.0888e+01,  4.2762e-01,  3.0511e+01, -6.6134e+00,  3.9080e+00,\n",
            "           2.1457e+01,  2.1087e+01, -2.9520e+01,  5.8783e+00,  3.0585e+01,\n",
            "          -3.0922e+00, -1.6363e+01, -2.7166e+01, -8.8279e+00,  1.7369e+01,\n",
            "          -7.5245e+00,  1.9780e+01, -1.0668e+01,  4.1661e+01,  1.8297e+01,\n",
            "          -3.1973e+01, -1.0396e+01,  1.8853e+01,  5.0777e+01,  2.4758e+01,\n",
            "          -3.3471e+00, -2.2312e+01, -1.8059e+01, -6.8795e+00, -7.0569e+00,\n",
            "           2.0346e+01, -1.8506e+01, -1.8044e+01,  1.7107e+01, -1.3727e+01,\n",
            "          -1.9402e+00,  1.2955e+01, -3.8421e+01,  1.9267e+01,  1.4306e+01,\n",
            "          -5.2014e+00, -3.0895e+01,  1.6449e+01, -2.8193e+01,  1.8023e+01,\n",
            "           3.0019e+00,  5.2734e+00, -4.7215e+01, -7.4680e-01, -2.1279e+01,\n",
            "          -2.1823e+00,  4.3182e+01,  2.9131e+01, -1.0060e+01, -2.7988e+01,\n",
            "          -1.1330e+01,  3.7140e+01, -2.1264e+01,  4.4287e+00, -2.2076e+01,\n",
            "          -2.9727e+00,  2.7097e+00, -3.1204e+00,  1.3895e+01, -1.5299e+01,\n",
            "           1.6461e+01, -3.5859e+01,  2.4369e+01, -5.3239e+00,  1.2628e+01,\n",
            "          -2.8196e+01,  1.1186e+01, -6.2712e-01,  2.0730e+01,  2.0843e+01,\n",
            "          -3.3266e+01, -3.0790e+01,  8.5162e+00,  3.1926e+00, -6.1707e+00,\n",
            "          -7.2838e+00, -3.6073e+01, -1.9172e+01,  4.6984e+00, -4.0629e+00,\n",
            "          -2.2534e+01, -8.6934e+00, -3.0304e+01,  7.0279e+00,  1.0483e+00,\n",
            "           4.5903e+01,  1.8864e+01,  1.0391e+01,  8.3962e+00,  5.2082e+01,\n",
            "          -7.6150e+00, -1.1926e+01,  9.2093e+00,  1.8495e+01, -1.6043e+01,\n",
            "           2.0133e+01, -4.3444e+00,  2.0766e+01,  4.6139e+00,  2.3181e+01,\n",
            "          -2.3671e+01, -1.5072e+01, -2.8981e+01,  1.2628e+01,  3.9807e+00,\n",
            "          -4.5378e+01,  2.5026e+01,  2.9552e+00,  4.0433e+01, -4.5159e+01,\n",
            "          -1.8112e+01, -1.2840e+01, -4.0708e+01,  5.6131e+01,  5.9475e-01,\n",
            "           2.5862e+01,  6.8725e+00, -1.6978e+00, -4.6364e+00,  1.6794e+01,\n",
            "          -5.2472e+00, -9.9898e+00, -3.5363e+01, -2.3497e+00,  1.0204e+01,\n",
            "          -2.5004e+01,  7.6240e+00, -3.8127e+00, -1.9374e+01, -2.5116e+01,\n",
            "          -3.8040e+00,  4.3999e+01,  1.8137e+01,  4.2748e+00, -1.2424e+00,\n",
            "           3.8045e+00, -4.7278e+01, -5.1636e+00, -3.1406e-02, -1.2008e+01,\n",
            "          -1.1527e+01,  5.8229e-01,  4.4599e+01, -4.4855e+01, -4.9090e+00,\n",
            "          -6.0770e+00, -1.9161e+01,  3.1767e+01,  1.6031e-01, -4.2371e+00,\n",
            "           1.4265e+01,  8.3853e+00, -4.1401e+01,  3.1617e+01, -1.2961e+01,\n",
            "          -1.7701e+01,  1.4471e+01,  1.0174e-01,  1.3750e+01, -1.5829e+01,\n",
            "           1.8772e+01, -4.5066e+00, -4.6798e+01, -1.3768e+01, -1.8732e+01,\n",
            "          -1.3085e+01, -3.5796e+01, -5.1496e+01,  7.9654e+00,  3.0609e+01,\n",
            "          -5.8099e+01, -1.8770e+01,  1.7524e+00,  3.2727e+01, -8.2499e+00,\n",
            "          -1.1778e+00, -9.5234e+00, -1.8938e+01,  2.4385e+01,  4.7039e+00,\n",
            "           1.8165e+01, -1.7965e+01,  1.8716e+01,  2.3689e+01,  1.0516e+01,\n",
            "          -1.4169e+01,  4.0985e+01,  5.3112e+00, -8.0065e+00,  1.1892e+01,\n",
            "           2.9486e+01, -2.0805e+01,  9.2973e+00,  4.2463e+01, -2.7330e+01,\n",
            "          -3.9095e+00, -1.8842e+01,  2.4001e+01, -1.6334e+01, -1.1047e+01,\n",
            "           1.4659e+01, -1.1675e+01,  3.6967e+01,  3.0665e+01, -1.6738e+01,\n",
            "           2.2955e+01, -1.0788e+01,  6.9832e+00, -1.1111e+01,  9.1811e+00,\n",
            "          -1.4203e+01,  1.6586e+00, -1.9824e+01, -3.3633e+01, -1.3471e+01,\n",
            "           4.5377e+01,  3.6142e-01,  3.2555e+01, -2.6047e+01, -1.2065e+01,\n",
            "           2.0625e+00,  6.9309e-01,  3.2084e+00, -3.2657e+01, -2.1050e+01,\n",
            "           3.2180e+01, -4.2827e+01,  1.7088e+01, -9.1197e+00,  2.6372e+01,\n",
            "           1.8874e+01, -2.7093e+01, -3.0511e+01,  1.4198e+01, -8.3716e+00,\n",
            "           7.5311e+01,  1.5256e+01, -2.0531e+01,  2.3273e+01, -1.4689e+01,\n",
            "          -3.6550e+01, -4.1464e+00,  8.2160e+00,  8.8222e+00, -7.5097e-01,\n",
            "          -3.2074e+00,  1.7832e+01,  1.3559e+01,  3.3966e+01,  6.7844e+00,\n",
            "          -7.2302e+00,  2.2420e+01,  2.6357e+01, -9.3827e+00,  5.8057e+00,\n",
            "           1.0855e+01, -1.0360e+01,  1.9662e+01, -2.0181e+01, -6.9148e+00,\n",
            "          -2.2860e+01,  5.8650e+01,  6.2886e+00, -2.9119e+01, -3.3921e+01,\n",
            "          -2.0643e+01, -4.7321e+00, -2.4747e+01, -3.3936e+01, -3.1510e+01,\n",
            "           1.2816e+01,  1.7917e+01, -9.0221e+00, -1.3993e+01,  2.1174e+01,\n",
            "           6.2209e-01, -1.1999e+01, -1.3710e+01, -3.2775e+00, -1.0443e+00,\n",
            "          -8.0989e+00,  2.2143e+01, -1.4092e+01,  5.8517e+00,  1.2273e+01,\n",
            "          -6.0461e+01, -2.0671e-02, -1.9202e+01,  5.6307e+01, -1.5737e+00,\n",
            "           1.3981e+00,  1.4000e+01, -3.2443e+00, -1.5889e+01,  1.7630e+01,\n",
            "          -3.8608e+01,  2.7000e+00,  1.5440e+01, -4.6787e+01,  1.7991e+01,\n",
            "          -9.7201e+00,  9.7134e+00,  5.9801e+00, -9.5009e+00, -1.8849e+01,\n",
            "          -8.1754e+00,  2.8588e+00,  1.2917e+01, -7.3374e-01,  2.5144e+01,\n",
            "           1.3151e+01,  1.5338e+01, -4.0073e+01, -1.0422e+00,  1.2885e+01,\n",
            "          -2.5978e+01, -2.2060e+01, -3.5698e+01, -7.3539e+00, -1.7058e+01,\n",
            "           3.9045e+00, -8.4479e+00,  3.0884e+01,  2.7074e+01,  2.4022e+01,\n",
            "          -1.5334e+01,  3.1622e+00,  1.2593e-01,  7.4735e+00, -2.5946e+01,\n",
            "           9.9413e+00,  2.4047e+01, -2.5470e+01,  1.0079e+01, -7.8727e+00,\n",
            "          -1.4123e+01,  1.3685e+01, -8.8118e+00, -1.5307e+01, -1.8896e+01,\n",
            "           2.2573e+01,  4.0508e+01,  1.0981e+01, -4.0211e-01, -3.4411e+01,\n",
            "           1.2868e+01, -1.0714e+01, -3.4347e+00, -3.7065e+00,  5.5902e+00,\n",
            "          -3.3010e+01,  8.9058e+00, -3.5771e+00,  4.2805e+01,  4.3532e+00,\n",
            "          -2.7364e+00,  1.5051e+01, -1.6193e+01,  6.2680e+01,  1.0263e-01,\n",
            "          -8.7478e+00, -7.1735e+00, -2.4649e+01,  2.5080e+01,  9.0863e+00,\n",
            "           4.8988e+01,  1.5266e+01, -6.4074e+01,  2.4283e+01, -6.1515e+01,\n",
            "          -1.5913e+00,  1.2818e+01, -5.1284e+00, -1.1728e+01, -1.7516e+01,\n",
            "           2.5461e+01, -4.2517e+01,  5.7028e+00, -1.9513e+01, -4.3254e+01,\n",
            "          -1.1814e+01,  2.4642e+01,  1.0629e+01, -4.0964e+00, -2.8524e+01,\n",
            "           2.6734e+01,  4.0267e+01,  7.2179e+00, -1.7040e+01, -3.4969e+00,\n",
            "           1.8964e+01, -1.5938e-01]]], grad_fn=<AddBackward0>)\n",
            "torch.Size([1, 1, 1])\n",
            "tensor([[[True]]])\n",
            "torch.Size([1, 1, 512])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def translate(model: nn.Module, source: Tensor, start_token: int, stop_token: int, seq_len: int):\n",
        "    src_pos_enc = model.positional(source.shape[1]).unsqueeze(0)\n",
        "    src_embedding = model.embed(source)\n",
        "    encoderInput = src_embedding + src_pos_enc\n",
        "\n",
        "    encoderOutput = model.encoderStack(encoderInput)\n",
        "    print(encoderOutput.shape)\n",
        "    print(encoderOutput)\n",
        "    sequence = torch.tensor([[start_token]], dtype=torch.int32)\n",
        "    print(sequence.shape)\n",
        "    print(sequence)\n",
        "    for _ in range(1):\n",
        "        \n",
        "        embedded_sequence = model.embed(sequence)\n",
        "        print(embedded_sequence.shape)\n",
        "        seq_pos_enc = model.positional(sequence.shape[1]).unsqueeze(0)\n",
        "        print(seq_pos_enc.shape)\n",
        "        decoderInput = embedded_sequence + seq_pos_enc\n",
        "        print(decoderInput.shape)\n",
        "        print(decoderInput)\n",
        "        subseq_mask = (torch.triu(torch.ones((1, sequence.shape[1], sequence.shape[1]), dtype=torch.int32), diagonal=1) == 0)\n",
        "        print(subseq_mask.shape)\n",
        "        print(subseq_mask)\n",
        "        decoderOutput = model.decoderStack(encoderOutput, decoderInput, subseq_mask)\n",
        "        print(decoderOutput.shape)\n",
        "        raw_word = decoderOutput[:, -1, :]\n",
        "\n",
        "        probs = model.generateProbs(raw_word)\n",
        "        '''all_probs = model.generateProbs(decoderOutput)\n",
        "        _, a = torch.max(probs, dim=1)\n",
        "        print(all_probs.shape)\n",
        "        print(a.data[0])\n",
        "        for i in range(all_probs.shape[1]):\n",
        "            print(torch.argmax(all_probs[:, :i+1, :], -1))'''\n",
        "        generated_word_id = torch.argmax(probs, dim=-1)\n",
        "        \n",
        "        generated_word_tensor = torch.tensor([[generated_word_id]], dtype=torch.int32)\n",
        "\n",
        "        sequence = torch.cat((sequence, generated_word_tensor), dim=1)\n",
        "\n",
        "        if generated_word_id == stop_token:\n",
        "            break\n",
        "    #print(sequence)\n",
        "    translation_ids = sequence.cpu().numpy()\n",
        "\n",
        "    translation = tokenizer.decode(translation_ids.squeeze())\n",
        "\n",
        "    return translation\n",
        "model.eval()\n",
        "translation = translate(model=model, source=src, start_token=BOS_IDX, stop_token=EOS_IDX, seq_len=MAX_LEN)\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR0Q2WoxmlKJ"
      },
      "outputs": [],
      "source": [
        "encoded_german = tokenizer.encode(\"Auf der Veranda spielt ein glücklicher Hund.\")\n",
        "german_id_arr = encoded_german.ids\n",
        "\n",
        "german = torch.tensor(german_id_arr).unsqueeze(0)\n",
        "print(german)\n",
        "print(german.shape)\n",
        "\n",
        "translation = translate(model, german, 2, 3, MAX_LEN)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6fb3815109fae185a2989dc67116c03680cdd5befd2823d06e43fcf705655cc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
